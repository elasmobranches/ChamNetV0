#!/usr/bin/env python3
# ============================================================================
# ESANet Sequential Models Parameter Count Measurement Script
# ============================================================================
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ESANet ëª¨ë¸ë“¤ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
# ì£¼ìš” ê¸°ëŠ¥:
# - ì˜ë¯¸ ë¶„í•  ëª¨ë¸ê³¼ ê¹Šì´ ì¶”ì • ëª¨ë¸ì˜ ê°œë³„ íŒŒë¼ë¯¸í„° ìˆ˜ ì¸¡ì •
# - ìˆœì°¨ ì‹¤í–‰ ì‹œ ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
# - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„
# - ëª¨ë¸ ë³µì¡ë„ ë¹„êµ

import os
import sys
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, Tuple, Optional
import argparse

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ============================================================================
# ì‹¤ì œ í•™ìŠµ ì½”ë“œì—ì„œ ëª¨ë¸ import
# ============================================================================
try:
    from models.train_esanet_seg_only import LightningESANetSegOnly
    SEG_MODEL_AVAILABLE = True
    print("âœ… LightningESANetSegOnly ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ LightningESANetSegOnly ëª¨ë¸ import ì‹¤íŒ¨: {e}")
    SEG_MODEL_AVAILABLE = False

try:
    from models.train_esanet_depth_only import LightningESANetDepthOnly
    DEPTH_MODEL_AVAILABLE = True
    print("âœ… LightningESANetDepthOnly ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ LightningESANetDepthOnly ëª¨ë¸ import ì‹¤íŒ¨: {e}")
    DEPTH_MODEL_AVAILABLE = False

try:
    from models.train_esanet_mtl_uncertain import LightningESANetMTL
    MTL_MODEL_AVAILABLE = True
    print("âœ… LightningESANetMTL ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ LightningESANetMTL ëª¨ë¸ import ì‹¤íŒ¨: {e}")
    MTL_MODEL_AVAILABLE = False


# ============================================================================
# íŒŒë¼ë¯¸í„° ìˆ˜ ì¸¡ì • í•¨ìˆ˜ë“¤
# ============================================================================
def count_parameters(model: nn.Module) -> Dict[str, int]:
    """
    ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        model: ì¸¡ì •í•  ëª¨ë¸
        
    Returns:
        Dict[str, int]: íŒŒë¼ë¯¸í„° ìˆ˜ ì •ë³´
            - total: ì´ íŒŒë¼ë¯¸í„° ìˆ˜
            - trainable: í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜
            - frozen: ê³ ì •ëœ íŒŒë¼ë¯¸í„° ìˆ˜
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    frozen_params = total_params - trainable_params
    
    return {
        "total": total_params,
        "trainable": trainable_params,
        "frozen": frozen_params
    }


def format_number(num: int) -> str:
    """
    ìˆ«ìë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    
    Args:
        num: í¬ë§·íŒ…í•  ìˆ«ì
        
    Returns:
        str: í¬ë§·íŒ…ëœ ë¬¸ìì—´ (ì˜ˆ: "15.2M", "1.5B")
    """
    if num >= 1e9:
        return f"{num/1e9:.1f}B"
    elif num >= 1e6:
        return f"{num/1e6:.1f}M"
    elif num >= 1e3:
        return f"{num/1e3:.1f}K"
    else:
        return str(num)


def estimate_memory_usage(model: nn.Module, input_shape: Tuple[int, ...]) -> Dict[str, float]:
    """
    ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¶”ì •í•©ë‹ˆë‹¤.
    
    Args:
        model: ì¸¡ì •í•  ëª¨ë¸
        input_shape: ì…ë ¥ í…ì„œì˜ í˜•íƒœ
        
    Returns:
        Dict[str, float]: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì •ë³´ (MB)
            - model_params: ëª¨ë¸ íŒŒë¼ë¯¸í„° ë©”ëª¨ë¦¬
            - model_buffers: ëª¨ë¸ ë²„í¼ ë©”ëª¨ë¦¬
            - input_memory: ì…ë ¥ í…ì„œ ë©”ëª¨ë¦¬
            - total: ì´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    """
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë©”ëª¨ë¦¬ (float32 ê¸°ì¤€)
    param_memory = sum(p.numel() * 4 for p in model.parameters()) / (1024 * 1024)  # MB
    
    # ëª¨ë¸ ë²„í¼ ë©”ëª¨ë¦¬ (BatchNorm í†µê³„ ë“±)
    buffer_memory = sum(b.numel() * 4 for b in model.buffers()) / (1024 * 1024)  # MB
    
    # ì…ë ¥ í…ì„œ ë©”ëª¨ë¦¬
    input_memory = torch.tensor(input_shape).numel() * 4 / (1024 * 1024)  # MB
    
    total_memory = param_memory + buffer_memory + input_memory
    
    return {
        "model_params": param_memory,
        "model_buffers": buffer_memory,
        "input_memory": input_memory,
        "total": total_memory
    }


def load_model_from_checkpoint(checkpoint_path: str, model_class, device: str = "cpu") -> nn.Module:
    """
    ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
        model_class: ëª¨ë¸ í´ë˜ìŠ¤
        device: ë””ë°”ì´ìŠ¤
        
    Returns:
        nn.Module: ë¡œë“œëœ ëª¨ë¸
    """
    try:
        model = model_class.load_from_checkpoint(checkpoint_path, map_location=device)
        model.eval()
        return model
    except Exception as e:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def measure_sequential_models(seg_ckpt_path: str, depth_ckpt_path: str, 
                            height: int = 512, width: int = 512,
                            device: str = "cpu") -> None:
    """
    ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ëª¨ë¸ë“¤ì˜ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
    
    Args:
        seg_ckpt_path: ì˜ë¯¸ ë¶„í•  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        depth_ckpt_path: ê¹Šì´ ì¶”ì • ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ
        height: ì…ë ¥ ì´ë¯¸ì§€ ë†’ì´
        width: ì…ë ¥ ì´ë¯¸ì§€ ë„ˆë¹„
        device: ë””ë°”ì´ìŠ¤
    """
    print("="*80)
    print("ESANet ìˆœì°¨ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¸¡ì •")
    print("="*80)
    
    # 1. ì˜ë¯¸ ë¶„í•  ëª¨ë¸ ì¸¡ì •
    print("\nğŸ” ì˜ë¯¸ ë¶„í•  ëª¨ë¸ ë¶„ì„...")
    if SEG_MODEL_AVAILABLE:
        seg_model = load_model_from_checkpoint(seg_ckpt_path, LightningESANetSegOnly, device)
        if seg_model is not None:
            seg_params = count_parameters(seg_model)
            seg_memory = estimate_memory_usage(seg_model, (1, 3, height, width))
            
            print(f"  ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜:")
            print(f"    - ì´ íŒŒë¼ë¯¸í„°: {format_number(seg_params['total'])} ({seg_params['total']:,})")
            print(f"    - í•™ìŠµ ê°€ëŠ¥: {format_number(seg_params['trainable'])} ({seg_params['trainable']:,})")
            print(f"    - ê³ ì •ë¨: {format_number(seg_params['frozen'])} ({seg_params['frozen']:,})")
            print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
            print(f"    - ëª¨ë¸ íŒŒë¼ë¯¸í„°: {seg_memory['model_params']:.2f} MB")
            print(f"    - ëª¨ë¸ ë²„í¼: {seg_memory['model_buffers']:.2f} MB")
            print(f"    - ì…ë ¥ í…ì„œ: {seg_memory['input_memory']:.2f} MB")
            print(f"    - ì´ ë©”ëª¨ë¦¬: {seg_memory['total']:.2f} MB")
        else:
            print("  âŒ ì˜ë¯¸ ë¶„í•  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            seg_params = {"total": 0, "trainable": 0, "frozen": 0}
            seg_memory = {"total": 0}
    else:
        print("  âŒ ì˜ë¯¸ ë¶„í•  ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        seg_params = {"total": 0, "trainable": 0, "frozen": 0}
        seg_memory = {"total": 0}
    
    # 2. ê¹Šì´ ì¶”ì • ëª¨ë¸ ì¸¡ì •
    print("\nğŸ” ê¹Šì´ ì¶”ì • ëª¨ë¸ ë¶„ì„...")
    if DEPTH_MODEL_AVAILABLE:
        depth_model = load_model_from_checkpoint(depth_ckpt_path, LightningESANetDepthOnly, device)
        if depth_model is not None:
            depth_params = count_parameters(depth_model)
            depth_memory = estimate_memory_usage(depth_model, (1, 3, height, width))
            
            print(f"  ğŸ“Š íŒŒë¼ë¯¸í„° ìˆ˜:")
            print(f"    - ì´ íŒŒë¼ë¯¸í„°: {format_number(depth_params['total'])} ({depth_params['total']:,})")
            print(f"    - í•™ìŠµ ê°€ëŠ¥: {format_number(depth_params['trainable'])} ({depth_params['trainable']:,})")
            print(f"    - ê³ ì •ë¨: {format_number(depth_params['frozen'])} ({depth_params['frozen']:,})")
            print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
            print(f"    - ëª¨ë¸ íŒŒë¼ë¯¸í„°: {depth_memory['model_params']:.2f} MB")
            print(f"    - ëª¨ë¸ ë²„í¼: {depth_memory['model_buffers']:.2f} MB")
            print(f"    - ì…ë ¥ í…ì„œ: {depth_memory['input_memory']:.2f} MB")
            print(f"    - ì´ ë©”ëª¨ë¦¬: {depth_memory['total']:.2f} MB")
        else:
            print("  âŒ ê¹Šì´ ì¶”ì • ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            depth_params = {"total": 0, "trainable": 0, "frozen": 0}
            depth_memory = {"total": 0}
    else:
        print("  âŒ ê¹Šì´ ì¶”ì • ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        depth_params = {"total": 0, "trainable": 0, "frozen": 0}
        depth_memory = {"total": 0}
    
    # 3. ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ê³¼ ë¹„êµ (ì„ íƒì‚¬í•­)
    print("\nğŸ” ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ê³¼ ë¹„êµ...")
    if MTL_MODEL_AVAILABLE:
        # ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ì€ ì²´í¬í¬ì¸íŠ¸ ì—†ì´ ìƒˆë¡œ ìƒì„±
        try:
            mtl_model = LightningESANetMTL(
                height=height,
                width=width,
                num_classes=7,
                encoder_rgb='resnet34',
                encoder_depth='resnet34',
                encoder_block='NonBottleneck1D',
                use_uncertainty_weighting=True,
                use_dwa_weighting=False,
            )
            mtl_params = count_parameters(mtl_model)
            mtl_memory = estimate_memory_usage(mtl_model, (1, 3, height, width))
            
            print(f"  ğŸ“Š ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜:")
            print(f"    - ì´ íŒŒë¼ë¯¸í„°: {format_number(mtl_params['total'])} ({mtl_params['total']:,})")
            print(f"    - í•™ìŠµ ê°€ëŠ¥: {format_number(mtl_params['trainable'])} ({mtl_params['trainable']:,})")
            print(f"    - ê³ ì •ë¨: {format_number(mtl_params['frozen'])} ({mtl_params['frozen']:,})")
            print(f"  ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mtl_memory['total']:.2f} MB")
        except Exception as e:
            print(f"  âŒ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {e}")
            mtl_params = {"total": 0, "trainable": 0, "frozen": 0}
            mtl_memory = {"total": 0}
    else:
        print("  âŒ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        mtl_params = {"total": 0, "trainable": 0, "frozen": 0}
        mtl_memory = {"total": 0}
    
    # 4. ìˆœì°¨ ì‹¤í–‰ ì‹œ ì´ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    print("\n" + "="*80)
    print("ìˆœì°¨ ì‹¤í–‰ ë¶„ì„ ê²°ê³¼")
    print("="*80)
    
    sequential_total = seg_params['total'] + depth_params['total']
    sequential_trainable = seg_params['trainable'] + depth_params['trainable']
    sequential_frozen = seg_params['frozen'] + depth_params['frozen']
    sequential_memory = seg_memory['total'] + depth_memory['total']
    
    print(f"ğŸ“Š ìˆœì°¨ ì‹¤í–‰ (ì˜ë¯¸ ë¶„í•  + ê¹Šì´ ì¶”ì •):")
    print(f"  - ì´ íŒŒë¼ë¯¸í„°: {format_number(sequential_total)} ({sequential_total:,})")
    print(f"  - í•™ìŠµ ê°€ëŠ¥: {format_number(sequential_trainable)} ({sequential_trainable:,})")
    print(f"  - ê³ ì •ë¨: {format_number(sequential_frozen)} ({sequential_frozen:,})")
    print(f"  - ì´ ë©”ëª¨ë¦¬: {sequential_memory:.2f} MB")
    
    print(f"\nğŸ“Š ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸:")
    print(f"  - ì´ íŒŒë¼ë¯¸í„°: {format_number(mtl_params['total'])} ({mtl_params['total']:,})")
    print(f"  - í•™ìŠµ ê°€ëŠ¥: {format_number(mtl_params['trainable'])} ({mtl_params['trainable']:,})")
    print(f"  - ê³ ì •ë¨: {format_number(mtl_params['frozen'])} ({mtl_params['frozen']:,})")
    print(f"  - ì´ ë©”ëª¨ë¦¬: {mtl_memory['total']:.2f} MB")
    
    # 5. íš¨ìœ¨ì„± ë¶„ì„
    print(f"\nğŸ“ˆ íš¨ìœ¨ì„± ë¶„ì„:")
    if mtl_params['total'] > 0:
        param_efficiency = (sequential_total / mtl_params['total']) * 100
        memory_efficiency = (sequential_memory / mtl_memory['total']) * 100
        
        print(f"  - íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±: {param_efficiency:.1f}% (ìˆœì°¨/ë©€í‹°íƒœìŠ¤í¬)")
        print(f"  - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: {memory_efficiency:.1f}% (ìˆœì°¨/ë©€í‹°íƒœìŠ¤í¬)")
        
        if param_efficiency > 100:
            print(f"  - ìˆœì°¨ ì‹¤í–‰ì´ ë©€í‹°íƒœìŠ¤í¬ë³´ë‹¤ {param_efficiency-100:.1f}% ë” ë§ì€ íŒŒë¼ë¯¸í„° ì‚¬ìš©")
        else:
            print(f"  - ë©€í‹°íƒœìŠ¤í¬ê°€ ìˆœì°¨ ì‹¤í–‰ë³´ë‹¤ {100-param_efficiency:.1f}% ë” ë§ì€ íŒŒë¼ë¯¸í„° ì‚¬ìš©")
    
    print("="*80)


def main():
    parser = argparse.ArgumentParser(description="ESANet ìˆœì°¨ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¸¡ì •")
    parser.add_argument("--seg_ckpt", type=str, required=True, help="ì˜ë¯¸ ë¶„í•  ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    parser.add_argument("--depth_ckpt", type=str, required=True, help="ê¹Šì´ ì¶”ì • ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ")
    parser.add_argument("--height", type=int, default=512, help="ì…ë ¥ ì´ë¯¸ì§€ ë†’ì´")
    parser.add_argument("--width", type=int, default=512, help="ì…ë ¥ ì´ë¯¸ì§€ ë„ˆë¹„")
    parser.add_argument("--device", type=str, default="cpu", help="ë””ë°”ì´ìŠ¤ (cpu/cuda)")
    
    args = parser.parse_args()
    
    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(args.seg_ckpt):
        print(f"âŒ ì˜ë¯¸ ë¶„í•  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.seg_ckpt}")
        return
    
    if not os.path.exists(args.depth_ckpt):
        print(f"âŒ ê¹Šì´ ì¶”ì • ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.depth_ckpt}")
        return
    
    measure_sequential_models(
        seg_ckpt_path=args.seg_ckpt,
        depth_ckpt_path=args.depth_ckpt,
        height=args.height,
        width=args.width,
        device=args.device
    )


if __name__ == "__main__":
    main()
