import argparse
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
import csv

import numpy as np
import pytorch_lightning as pl
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from PIL.Image import Image as PILImage
import torchvision.transforms as T
import torchvision.transforms.functional as TF
from torch.utils.data import DataLoader, Dataset



# torchmetrics ë¼ì´ë¸ŒëŸ¬ë¦¬ import (íš¨ìœ¨ì ì¸ ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ìœ„í•´)
# IoU, MSE ë“±ì˜ ë©”íŠ¸ë¦­ì„ GPUì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°
try:
    from torchmetrics import JaccardIndex, MeanSquaredError, MeanAbsoluteError
    TORCHMETRICS_AVAILABLE = True
    print("âœ… torchmetricsë¥¼ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError:
    print("âš ï¸ torchmetricsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install torchmetricsë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    TORCHMETRICS_AVAILABLE = False

# PyTorch Lightning ê´€ë ¨ import
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
from pytorch_lightning.loggers import TensorBoardLogger
import time

# PIL ê¸°ë°˜ ì‹œê°í™” ì‚¬ìš© (torchvision.utils ì œê±°ë¨)

# í•™ìŠµ ê³¡ì„  ì €ì¥ì„ ìœ„í•œ matplotlib import
import matplotlib.pyplot as plt

# ESANet ëª¨ë¸ import
# ESANetì€ RGBì™€ Depthë¥¼ ë¶„ë¦¬ëœ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” íš¨ìœ¨ì ì¸ ë©€í‹°íƒœìŠ¤í¬ ì•„í‚¤í…ì²˜
sys.path.append('/home/shinds/my_document/DLFromScratch5/test/vae/sss/ESANet')
try:
    from src.models.model import ESANet
    ESANET_AVAILABLE = True
    print("âœ… ESANet ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ ESANet ëª¨ë¸ import ì‹¤íŒ¨: {e}")
    ESANET_AVAILABLE = False


# ============================================================================
# ìƒìˆ˜ ì •ì˜
# ============================================================================
# ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë˜ìŠ¤ ìˆ˜ (ë°°ê²½ + 6ê°œ ê°ì²´ í´ë˜ìŠ¤)
NUM_CLASSES = 7

# í´ë˜ìŠ¤ IDì™€ ë¼ë²¨ëª… ë§¤í•‘
# ê° í´ë˜ìŠ¤ëŠ” ê³ ìœ í•œ ìƒ‰ìƒìœ¼ë¡œ ì‹œê°í™”ë¨
ID2LABEL: Dict[int, str] = {
    0: "background",    # ë°°ê²½ (ê²€ì€ìƒ‰)
    1: "chamoe",        # ì°¸ì™¸ (ë…¸ë€ìƒ‰)
    2: "heatpipe",      # íˆíŠ¸íŒŒì´í”„ (ë¹¨ê°„ìƒ‰)
    3: "path",          # ê²½ë¡œ (ì´ˆë¡ìƒ‰)
    4: "pillar",        # ê¸°ë‘¥ (íŒŒë€ìƒ‰)
    5: "topdownfarm",   # ìƒí•˜ë†ì¥ (ìí™ìƒ‰)
    6: "unknown",       # ë¯¸ë¶„ë¥˜ (íšŒìƒ‰)
}


# ============================================================================
# ì¬í˜„ì„± ë° ê²°ì •ë¡  ìœ í‹¸ë¦¬í‹°
# ============================================================================
def set_global_determinism(seed: int = 42) -> None:
    """
    ì‹¤í—˜ì˜ ì¬í˜„ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    
    Args:
        seed: ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)
    
    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒì„ ì„¤ì •í•©ë‹ˆë‹¤:
    - Python ë‚´ì¥ random ëª¨ë“ˆ ì‹œë“œ
    - NumPy ëœë¤ ì‹œë“œ
    - PyTorch CPU ì‹œë“œ
    - PyTorch CUDA ì‹œë“œ (ëª¨ë“  GPU)
    - cuDNN ê²°ì •ë¡ ì  ëª¨ë“œ
    - PyTorch ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜ (ì§€ì›ë˜ì§€ ì•ŠëŠ” ì—°ì‚°ì€ ê²½ê³ ë§Œ ì¶œë ¥)
    """
    import random
    random.seed(seed)
    np.random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # cuDNN ìµœì í™” ëª¨ë“œ ì„¤ì • (ì„±ëŠ¥ ìš°ì„ )
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.deterministic = False


def dataloader_worker_init_fn(worker_id: int) -> None:
    """
    DataLoaderì˜ ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ì— ì¼ê´€ëœ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    
    Args:
        worker_id: ì›Œì»¤ ID (PyTorchì—ì„œ ìë™ìœ¼ë¡œ í• ë‹¹)
    
    ê° ì›Œì»¤ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì‹œë“œë¥¼ ê°€ì§€ì§€ë§Œ, ì¬ì‹œì‘ ì‹œì—ë„ ë™ì¼í•œ ì‹œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì´ë¥¼ í†µí•´ ë°ì´í„° ì…”í”Œë§ê³¼ ì¦ê°•ì˜ ì¬í˜„ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    # torch.initial_seed()ëŠ” ì´ë¯¸ ì›Œì»¤ë§ˆë‹¤ ë‹¤ë¥¸ ê°’ì„ ê°€ì§
    # ì´ë¥¼ numpy/python ì‹œë“œì™€ ë™ê¸°í™”
    worker_seed = torch.initial_seed() % 2**32
    import random
    random.seed(worker_seed)
    np.random.seed(worker_seed)

# ============================================================================
# RGB+Depth ë©€í‹°íƒœìŠ¤í¬ ë°ì´í„°ì…‹ (ë¶„ë¦¬ëœ ì…ë ¥)
# ============================================================================
class RGBDepthMultiTaskDataset(Dataset):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ RGB/Depth ë©€í‹°íƒœìŠ¤í¬ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.
    
    ì£¼ìš” íŠ¹ì§•:
    - ESANet ì•„í‚¤í…ì²˜ì— ë§ê²Œ RGBì™€ Depthë¥¼ ë¶„ë¦¬ëœ ì…ë ¥ìœ¼ë¡œ ì œê³µ
    - albumentationsë¥¼ í™œìš©í•œ ê³ ê¸‰ ë°ì´í„° ì¦ê°• ì§€ì›
    - í•™ìŠµ ì‹œ ìƒ‰ìƒ ì¦ê°•(RGBë§Œ)ê³¼ ê¸°í•˜í•™ì  ì¦ê°•(RGB/Depth/Mask ëª¨ë‘) ë¶„ë¦¬ ì ìš©
    - ê¹Šì´ ë°ì´í„°ì˜ ì •ê·œí™” ë° ì „ì²˜ë¦¬ ìë™í™”
    
    ë°˜í™˜ ë°ì´í„°:
    - RGB í…ì„œ: [3, H, W] ì •ê·œí™”ëœ RGB ì´ë¯¸ì§€
    - Depth í…ì„œ: [1, H, W] ì •ê·œí™”ëœ ê¹Šì´ ë§µ
    - ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬: [H, W] í´ë˜ìŠ¤ ë¼ë²¨
    - ê¹Šì´ ì •ë‹µ: [H, W] ê¹Šì´ íƒ€ê²Ÿ (ì‹œê°í™”ìš©)
    - íŒŒì¼ëª…: ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ëª…
    """
    def __init__(
        self,
        images_dir: Path,
        masks_dir: Path,
        depth_dir: Path,
        image_size: Tuple[int, int],
        mean: List[float],
        std: List[float],
        is_train: bool = False,
    ) -> None:
        """
        ë°ì´í„°ì…‹ ì´ˆê¸°í™”
        
        Args:
            images_dir: RGB ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            masks_dir: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            depth_dir: ê¹Šì´ ë§µ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            image_size: ëª¨ë¸ ì…ë ¥ í¬ê¸° (width, height)
            mean: ImageNet ì •ê·œí™” í‰ê· ê°’ [R, G, B]
            std: ImageNet ì •ê·œí™” í‘œì¤€í¸ì°¨ [R, G, B]
            is_train: í•™ìŠµ ëª¨ë“œ ì—¬ë¶€ (í˜„ì¬ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)
        """
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.depth_dir = depth_dir
        self.image_size = image_size
        self.mean = mean
        self.std = std
        self.is_train = is_train

        # ì§€ì›ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ìë¡œ íŒŒì¼ ëª©ë¡ ìƒì„±
        # JPG, JPEG, PNG í˜•ì‹ ì§€ì›
        self.image_files: List[str] = [
            f for f in sorted(os.listdir(images_dir)) if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ]
        if len(self.image_files) == 0:
            raise RuntimeError(f"No images in {images_dir}")

        print(f"ğŸ“ Dataset loaded: {len(self.image_files)} images from {images_dir}")

    def __len__(self) -> int:
        return len(self.image_files)

    def __getitem__(self, idx: int):
        """
        ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œì„ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬/ì¦ê°•/í…ì„œí™”í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        ì²˜ë¦¬ ìˆœì„œ:
        1) íŒŒì¼ ê²½ë¡œ ìƒì„± ë° ì¡´ì¬ í™•ì¸ (RGB/Mask/Depth)
        2) PIL ì´ë¯¸ì§€ ë¡œë“œ ë° ê¹Šì´ ìŠ¤ì¼€ì¼ ì •ê·œí™” (0~1 ë²”ìœ„)
        3) ê¸°ë³¸ ë¦¬ì‚¬ì´ì¦ˆ (ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •)
        4) (í•™ìŠµ ëª¨ë“œ && albumentations í™œì„±) ì¦ê°• ë¶„ë¦¬ ì ìš©
           - RGB ì „ìš©: ë°ê¸°/ëŒ€ë¹„/ê°€ìš°ì‹œì•ˆë…¸ì´ì¦ˆ/ê°ë§ˆ/HSV ë“± (ê¹Šì´/ë§ˆìŠ¤í¬ëŠ” ì œì™¸)
           - ê¸°í•˜í•™ì : ì¢Œìš°ë°˜ì „/íšŒì „/ìŠ¤ì¼€ì¼/ì—˜ë¼ìŠ¤í‹± (RGB/Depth/Mask ë™ì¼ ë³€í™˜)
        5) ì¦ê°• ì´í›„ í¬ê¸° ë³´ì • (ë°°ì¹˜ ìŠ¤íƒì„ ìœ„í•´ HxW ê³ ì •)
        6) í…ì„œ ë³€í™˜ ë° ì •ê·œí™”, Depth íƒ€ê¹ƒ ìƒì„±
        
        Args:
            idx: ìƒ˜í”Œ ì¸ë±ìŠ¤
            
        Returns:
            tuple: (image[3,H,W], depth[1,H,W], mask[H,W], depth_target[H,W], filename)
                - image: ì •ê·œí™”ëœ RGB ì´ë¯¸ì§€ í…ì„œ
                - depth: ì •ê·œí™”ëœ ê¹Šì´ ë§µ í…ì„œ
                - mask: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ í…ì„œ
                - depth_target: ê¹Šì´ íƒ€ê²Ÿ í…ì„œ (ì‹œê°í™”ìš©)
                - filename: ì›ë³¸ íŒŒì¼ëª…
        """
        img_name = self.image_files[idx]
        img_path = self.images_dir / img_name
        
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  stem ì¶”ì¶œ
        # ì˜ˆ: "image001.jpg" -> "image001"
        img_stem = Path(img_name).stem
        
        # ë§ˆìŠ¤í¬ íŒŒì¼ ê²½ë¡œ: {stem}_mask.png
        # ì˜ˆ: "image001" -> "image001_mask.png"
        mask_name = f"{img_stem}_mask.png"
        mask_path = self.masks_dir / mask_name
        
        # ê¹Šì´ íŒŒì¼ ê²½ë¡œ: {stem}_depth.png  
        # ì˜ˆ: "image001" -> "image001_depth.png"
        depth_name = f"{img_stem}_depth.png"
        depth_path = self.depth_dir / depth_name

        # íŒŒì¼ ì¡´ì¬ í™•ì¸ (í•„ìˆ˜ íŒŒì¼ë“¤ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ)
        if not mask_path.exists():
            raise FileNotFoundError(f"Mask file not found: {mask_path}")
        if not depth_path.exists():
            raise FileNotFoundError(f"Depth file not found: {depth_path}")

        # PIL ì´ë¯¸ì§€ë¡œ ë°ì´í„° ë¡œë“œ
        # RGB ì´ë¯¸ì§€ëŠ” 3ì±„ë„ë¡œ ë³€í™˜, ë§ˆìŠ¤í¬ëŠ” ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")
        depth_img = Image.open(depth_path)
        
        # ê¹Šì´ ì´ë¯¸ì§€ë¥¼ ì •ê·œí™”ëœ float ë°°ì—´ë¡œ ë³€í™˜
        # ë‹¤ì–‘í•œ ê¹Šì´ ì´ë¯¸ì§€ í¬ë§· ì§€ì› (16ë¹„íŠ¸, 8ë¹„íŠ¸, ê·¸ë ˆì´ìŠ¤ì¼€ì¼)
        if depth_img.mode == 'I;16':
            # 16ë¹„íŠ¸ ê¹Šì´ ì´ë¯¸ì§€: 0-65535 ë²”ìœ„ë¥¼ 0-1ë¡œ ì •ê·œí™”
            depth = np.array(depth_img, dtype=np.float32) / 65535.0
        elif depth_img.mode == 'I':
            # 32ë¹„íŠ¸ ì •ìˆ˜ ê¹Šì´ ì´ë¯¸ì§€: ìµœëŒ€ê°’ìœ¼ë¡œ ì •ê·œí™”
            depth = np.array(depth_img, dtype=np.float32)
            if depth.max() > 1.0:
                depth = depth / depth.max()
        else:
            # ê¸°íƒ€ í¬ë§·: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ í›„ 0-255 ë²”ìœ„ë¥¼ 0-1ë¡œ ì •ê·œí™” 
            # ìš°ë¦¬ëŠ” ì´ê±° ì‚¬ìš©í•¨
            depth = np.array(depth_img.convert('L'), dtype=np.float32) / 255.0
        
        # ì •ê·œí™”ëœ ê¹Šì´ ë°°ì—´ì„ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
        depth = Image.fromarray(depth)

        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± ìœ ì§€)
        # RGBì™€ ê¹Šì´ëŠ” BILINEAR ë³´ê°„, ë§ˆìŠ¤í¬ëŠ” NEAREST ë³´ê°„ ì‚¬ìš©
        image = TF.resize(image, [self.image_size[1], self.image_size[0]], interpolation=T.InterpolationMode.BILINEAR)
        mask = TF.resize(mask, [self.image_size[1], self.image_size[0]], interpolation=T.InterpolationMode.NEAREST)
        depth = TF.resize(depth, [self.image_size[1], self.image_size[0]], interpolation=T.InterpolationMode.BILINEAR)

        # PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜ (ë…ë¦½ì ì´ê³  ë¦¬ì‚¬ì´ì¦ˆ ê°€ëŠ¥í•œ ìŠ¤í† ë¦¬ì§€ ë³´ì¥)
        image = TF.to_tensor(image).contiguous().clone()  # [3, H, W] in [0, 1]
        depth_tensor = torch.from_numpy(np.array(depth, dtype=np.float32)).contiguous().clone()  # [H, W]
        mask = torch.from_numpy(np.array(mask, dtype=np.int64)).contiguous().clone()  # [H, W]

        # ImageNet í‘œì¤€ìœ¼ë¡œ RGB ì´ë¯¸ì§€ ì •ê·œí™”
        # mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
        image = TF.normalize(image, mean=self.mean, std=self.std)
        
        # ESANetì€ RGBì™€ Depthë¥¼ ë¶„ë¦¬ëœ í…ì„œë¡œ ë°›ìŒ
        # ê¹Šì´ í…ì„œì— ì±„ë„ ì°¨ì› ì¶”ê°€: [H, W] -> [1, H, W]
        depth_tensor = depth_tensor.unsqueeze(0).contiguous()  # [1, H, W]
        
        # depth_targetì€ ì´ë¯¸ contiguous()ë¡œ ë…ë¦½ì  ìŠ¤í† ë¦¬ì§€ ë³´ì¥ë¨
        depth_target = depth_tensor.squeeze(0)

        return image, depth_tensor, mask, depth_target, img_name  # RGB, Depth, Mask, Depth_target, filename


def get_preprocessing_params(encoder_name: str) -> Tuple[List[float], List[float]]:
    """
    ì¸ì½”ë” ì „ì²˜ë¦¬ ì •ê·œí™” íŒŒë¼ë¯¸í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤ (ImageNet í‘œì¤€).
    
    Args:
        encoder_name: ì¸ì½”ë” ì´ë¦„ (í˜„ì¬ëŠ” ì‚¬ìš©ë˜ì§€ ì•Šì§€ë§Œ í™•ì¥ì„±ì„ ìœ„í•´ ìœ ì§€)
        
    Returns:
        tuple: (mean, std) ì •ê·œí™” íŒŒë¼ë¯¸í„°
            - mean: [0.485, 0.456, 0.406] (R, G, B ì±„ë„ë³„ í‰ê· )
            - std:  [0.229, 0.224, 0.225] (R, G, B ì±„ë„ë³„ í‘œì¤€í¸ì°¨)
    
    Note:
        ESANetì€ ì¼ë°˜ì ìœ¼ë¡œ ImageNet ì‚¬ì „í›ˆë ¨ëœ ë°±ë³¸ì„ ì‚¬ìš©í•˜ë¯€ë¡œ
        ImageNet í‘œì¤€ ì •ê·œí™” íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    # ESANetì€ ì¼ë°˜ì ìœ¼ë¡œ ImageNet normalization ì‚¬ìš©
    return [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]




# ============================================================================
# ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë©”íŠ¸ë¦­ ëˆ„ì ê¸°
# ============================================================================
class MetricsAccumulator:
    """
    GPU ìƒì—ì„œ ë©”íŠ¸ë¦­ì„ ëˆ„ì í•˜ê³  ì—í­ ì¢…ë£Œ ì‹œ í•œ ë²ˆì— í‰ê· ì„ ê³„ì‚°í•˜ëŠ” ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëˆ„ì ê¸°ì…ë‹ˆë‹¤.
    
    ì‚¬ìš© ì´ìœ :
    - ìŠ¤í…ë§ˆë‹¤ CPUë¡œ ì „ì†¡/ì§‘ê³„ë¥¼ ë°˜ë³µí•˜ë©´ ì˜¤ë²„í—¤ë“œê°€ í¬ê²Œ ì¦ê°€
    - ì—í­ ëì—ì„œ í•œ ë²ˆì— í‰ê· ì„ ê³„ì‚°í•˜ì—¬ ì„±ëŠ¥/ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
    - GPU ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì—°ì‚°í•˜ì—¬ ë°ì´í„° ì „ì†¡ ë¹„ìš© ìµœì†Œí™”
    
    ì£¼ìš” íŠ¹ì§•:
    - GPUì—ì„œ ë©”íŠ¸ë¦­ ê°’ì„ ëˆ„ì  ì €ì¥
    - ì—í­ ì¢…ë£Œ ì‹œì—ë§Œ CPUë¡œ ì „ì†¡í•˜ì—¬ í‰ê·  ê³„ì‚°
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”ë¥¼ ìœ„í•œ ìë™ ë¦¬ì…‹ ê¸°ëŠ¥
    """
    def __init__(self, device: torch.device):
        """
        ë©”íŠ¸ë¦­ ëˆ„ì ê¸° ì´ˆê¸°í™”
        
        Args:
            device: ê³„ì‚° ë””ë°”ì´ìŠ¤ (GPU/CPU)
        """
        self.device = device
        self.metrics = {}  # ë©”íŠ¸ë¦­ë³„ ê°’ë“¤ì„ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        self.count = 0     # ì—…ë°ì´íŠ¸ íšŸìˆ˜ ì¹´ìš´í„°
        
    def update(self, **kwargs):
        """
        ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ê°’ë“¤ì„ ëˆ„ì ê¸°ì— ì¶”ê°€í•©ë‹ˆë‹¤ (GPUì—ì„œ ìœ ì§€)
        
        Args:
            **kwargs: ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ ê°’ì˜ í‚¤ì›Œë“œ ì¸ìˆ˜
        """
        for key, value in kwargs.items():
            if isinstance(value, torch.Tensor):
                # í…ì„œì¸ ê²½ìš°: ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ë¦¬í•˜ê³  GPUì— ìœ ì§€
                value = value.detach()
                if value.device != self.device:
                    value = value.to(self.device)
            else:
                # ìŠ¤ì¹¼ë¼ì¸ ê²½ìš°: í…ì„œë¡œ ë³€í™˜
                value = torch.tensor(value, device=self.device, dtype=torch.float32)
            
            # ë©”íŠ¸ë¦­ë³„ë¡œ ê°’ë“¤ì„ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
            if key not in self.metrics:
                self.metrics[key] = []
            self.metrics[key].append(value)
        
        self.count += 1
    
    def compute_mean(self) -> Dict[str, float]:
        """
        ëˆ„ì ëœ ëª¨ë“  ë©”íŠ¸ë¦­ì˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤ (CPUë¡œ í•œ ë²ˆë§Œ ì´ë™)
        
        Returns:
            Dict[str, float]: ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ í‰ê· ê°’ì˜ ë”•ì…”ë„ˆë¦¬
        """
        result = {}
        for key, values in self.metrics.items():
            if values:
                # ëª¨ë“  ê°’ì„ ìŠ¤íƒí•˜ê³  í‰ê·  ê³„ì‚°
                stacked = torch.stack(values)
                mean_value = stacked.mean()
                result[key] = float(mean_value.cpu().item())
        return result
    
    def reset(self):
        """
        ëˆ„ì ê¸°ë¥¼ ë¦¬ì…‹í•˜ê³  ë©”ëª¨ë¦¬ë¥¼ í•´ì œí•©ë‹ˆë‹¤
        """
        # ì €ì¥ëœ ëª¨ë“  í…ì„œë¥¼ ì‚­ì œí•˜ì—¬ ë©”ëª¨ë¦¬ í•´ì œ
        for key, values in self.metrics.items():
            if values:
                del values[:]  # ë¦¬ìŠ¤íŠ¸ ë‚´ìš© ì‚­ì œ
        self.metrics.clear()
        self.count = 0


# ============================================================================
# ë™ì  ê°€ì¤‘ì¹˜ í‰ê·  (DWA) ì†ì‹¤ ê°€ì¤‘ì¹˜ ì¡°ì •
# ============================================================================
class DynamicWeightAverage:
    """
    ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì„ ìœ„í•œ ë™ì  ê°€ì¤‘ì¹˜ í‰ê· (Dynamic Weight Average, DWA) í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ê° íƒœìŠ¤í¬ì˜ ìƒëŒ€ì  ì†ì‹¤ ê°ì†Œìœ¨ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ìë™ ì¡°ì •
    - íƒœìŠ¤í¬ ê°„ ë¶ˆê· í˜•ì„ í•´ê²°í•˜ì—¬ ëª¨ë“  íƒœìŠ¤í¬ê°€ ê· ë“±í•˜ê²Œ í•™ìŠµë˜ë„ë¡ í•¨
    - í•™ìŠµ ê³¼ì •ì—ì„œ ë™ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ì—¬ ì•ˆì •ì ì¸ í•™ìŠµ ë³´ì¥
    
    ì‘ë™ ì›ë¦¬:
    1. ê° íƒœìŠ¤í¬ì˜ ì†ì‹¤ ê°ì†Œìœ¨ì„ ê³„ì‚°
    2. ê°ì†Œìœ¨ì´ ë†’ì€ íƒœìŠ¤í¬ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
    3. Softmax í•¨ìˆ˜ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”í•˜ì—¬ í•©ì´ 1ì´ ë˜ë„ë¡ í•¨
    """
    def __init__(self, num_tasks: int = 2, temperature: float = 2.0, window_size: int = 10):
        """
        DWA ì´ˆê¸°í™”
        
        Args:
            num_tasks: íƒœìŠ¤í¬ ìˆ˜ (ê¸°ë³¸ê°’: 2, ì„¸ê·¸ë©˜í…Œì´ì…˜ + ê¹Šì´ ì¶”ì •)
            temperature: Softmax ì˜¨ë„ íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’: 2.0)
            window_size: ì†ì‹¤ íˆìŠ¤í† ë¦¬ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ê°’: 10)
        """
        self.num_tasks = num_tasks
        self.temperature = temperature
        self.window_size = window_size
        
        # ê° íƒœìŠ¤í¬ë³„ ì†ì‹¤ íˆìŠ¤í† ë¦¬ ì €ì¥
        self.loss_history = [[] for _ in range(num_tasks)]
        # ì´ˆê¸° ê°€ì¤‘ì¹˜: ëª¨ë“  íƒœìŠ¤í¬ì— ë™ì¼í•œ ê°€ì¤‘ì¹˜ (1/íƒœìŠ¤í¬ìˆ˜)
        self.weights = [1.0 / num_tasks] * num_tasks
        
    def update_weights(self, current_losses: List[float]) -> List[float]:
        """
        ìƒëŒ€ì  ì†ì‹¤ ê°ì†Œìœ¨ì„ ê¸°ë°˜ìœ¼ë¡œ íƒœìŠ¤í¬ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        Args:
            current_losses: ê° íƒœìŠ¤í¬ì˜ í˜„ì¬ ì†ì‹¤ ê°’ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[float]: ê° íƒœìŠ¤í¬ì˜ ì—…ë°ì´íŠ¸ëœ ê°€ì¤‘ì¹˜
        """
        # í˜„ì¬ ì†ì‹¤ê°’ì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        for i, loss in enumerate(current_losses):
            self.loss_history[i].append(loss)
            
        # ìµœê·¼ íˆìŠ¤í† ë¦¬ë§Œ ìœ ì§€ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
        for i in range(self.num_tasks):
            if len(self.loss_history[i]) > self.window_size:
                self.loss_history[i] = self.loss_history[i][-self.window_size:]
        
        # ìƒëŒ€ì  ê°ì†Œìœ¨ ê³„ì‚°
        if all(len(history) >= 2 for history in self.loss_history):
            decrease_rates = []
            for i in range(self.num_tasks):
                history = self.loss_history[i]
                # ìœˆë„ìš°ì— ëŒ€í•œ í‰ê·  ê°ì†Œìœ¨ ê³„ì‚°
                if len(history) >= 2:
                    decreases = []
                    for j in range(1, len(history)):
                        if history[j-1] > 0:
                            decrease = (history[j-1] - history[j]) / history[j-1]
                            decreases.append(max(0, decrease))  # ì–‘ìˆ˜ ê°ì†Œë§Œ ê³ ë ¤
                    
                    if decreases:
                        avg_decrease = sum(decreases) / len(decreases)
                        decrease_rates.append(avg_decrease)
                    else:
                        decrease_rates.append(0.0)
                else:
                    decrease_rates.append(0.0)
            
            # ì˜¨ë„ë¥¼ ì‚¬ìš©í•œ Softmaxë¡œ ê°€ì¤‘ì¹˜ ê³„ì‚° (LogSumExp íŠ¸ë¦­ìœ¼ë¡œ ìˆ˜ì¹˜ ì•ˆì •ì„± ê°œì„ )
            if any(rate > 0 for rate in decrease_rates):
                # ê°ì†Œìœ¨ ì •ê·œí™”
                max_rate = max(decrease_rates)
                if max_rate > 0:
                    normalized_rates = [rate / max_rate for rate in decrease_rates]
                else:
                    normalized_rates = [1.0] * self.num_tasks
                
                # ì˜¨ë„ ìŠ¤ì¼€ì¼ë§ ì ìš© ë° LogSumExp íŠ¸ë¦­ ì‚¬ìš©
                scaled_rates = torch.tensor(normalized_rates) / self.temperature
                max_scaled = scaled_rates.max()
                exp_rates = torch.exp(scaled_rates - max_scaled)  # ìˆ˜ì¹˜ ì•ˆì •ì„±
                self.weights = (exp_rates / exp_rates.sum()).tolist()
            else:
                # ê°ì†Œê°€ ì—†ìœ¼ë©´ ë™ì¼í•œ ê°€ì¤‘ì¹˜ ì‚¬ìš©
                self.weights = [1.0 / self.num_tasks] * self.num_tasks
        else:
            # ì¶©ë¶„í•œ íˆìŠ¤í† ë¦¬ê°€ ì—†ìœ¼ë©´ ë™ì¼í•œ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            self.weights = [1.0 / self.num_tasks] * self.num_tasks
        
        return self.weights.copy()
    
    def get_weights(self) -> List[float]:
        """
        í˜„ì¬ ê°€ì¤‘ì¹˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
        
        Returns:
            List[float]: ê° íƒœìŠ¤í¬ì˜ í˜„ì¬ ê°€ì¤‘ì¹˜
        """
        return self.weights.copy()


# ============================================================================
# ì†ì‹¤ í•¨ìˆ˜ë“¤
# ============================================================================
class SILogLoss(nn.Module):
    """
    ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ìŠ¤ì¼€ì¼ ë¶ˆë³€ ë¡œê·¸ ì†ì‹¤(Scale-Invariant Logarithmic Loss)ì…ë‹ˆë‹¤.
    
    ì£¼ìš” íŠ¹ì§•:
    - ìŠ¤ì¼€ì¼ ë¶ˆë³€ì„±: ê¹Šì´ ê°’ì˜ ì ˆëŒ€ì  í¬ê¸°ì— ê´€ê³„ì—†ì´ ìƒëŒ€ì  ì˜¤ì°¨ì— ì§‘ì¤‘
    - ë¡œê·¸ ê³µê°„ì—ì„œ ê³„ì‚°: ê¹Šì´ ê°’ì˜ ë¡œê·¸ ì°¨ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†ì‹¤ ê³„ì‚°
    - ë¶„ì‚° í•­: ë¡œê·¸ ì°¨ì´ì˜ ë¶„ì‚°ì„ ê³ ë ¤í•˜ì—¬ ë” ì•ˆì •ì ì¸ í•™ìŠµ
    
    ìˆ˜ì‹:
    SILog = (1/n) * Î£(log(pred) - log(target))Â² - Î» * (1/n) * Î£(log(pred) - log(target))Â²
    """
    def __init__(self, lambda_variance: float = 0.85, eps: float = 1e-6):
        """
        SILog ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™”
        
        Args:
            lambda_variance: ë¶„ì‚° í•­ì˜ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.85)
            eps: ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•œ ì‘ì€ ê°’ (ê¸°ë³¸ê°’: 1e-6)
        """
        super().__init__()
        self.lambda_variance = lambda_variance
        self.eps = eps

    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        SILog ì†ì‹¤ ê³„ì‚°
        
        Args:
            pred: ì˜ˆì¸¡ëœ ê¹Šì´ ë§µ [B, 1, H, W]
            target: ì •ë‹µ ê¹Šì´ ë§µ [B, H, W] ë˜ëŠ” [B, 1, H, W]
            mask: ìœ íš¨ í”½ì…€ ë§ˆìŠ¤í¬ [B, H, W] ë˜ëŠ” [B, 1, H, W] (ì„ íƒì‚¬í•­)
            
        Returns:
            torch.Tensor: SILog ì†ì‹¤ ê°’
        """
        # ì°¨ì› ì •ê·œí™”: [B, 1, H, W] -> [B, H, W]
        if pred.dim() == 4 and pred.shape[1] == 1:
            pred = pred.squeeze(1)
        if target.dim() == 4 and target.shape[1] == 1:
            target = target.squeeze(1)
        
        # ìœ íš¨í•œ ê¹Šì´ ê°’ì— ëŒ€í•œ ë§ˆìŠ¤í¬ ìƒì„±
        if mask is None:
            # ë§ˆìŠ¤í¬ê°€ ì—†ìœ¼ë©´ ìœ íš¨í•œ ê¹Šì´ ê°’ë§Œ ì‚¬ìš©
            valid_mask = (target > self.eps) & (torch.isfinite(target))
        else:
            # ë§ˆìŠ¤í¬ê°€ ìˆìœ¼ë©´ ë§ˆìŠ¤í¬ì™€ ìœ íš¨í•œ ê¹Šì´ ê°’ ëª¨ë‘ ê³ ë ¤
            if mask.dim() == 4 and mask.shape[1] == 1:
                mask = mask.squeeze(1)
            valid_mask = (target > self.eps) & (torch.isfinite(target)) & (mask > 0.5)
        
        # ìœ íš¨í•œ í”½ì…€ì´ ì—†ìœ¼ë©´ ì†ì‹¤ 0 ë°˜í™˜
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=pred.device, dtype=pred.dtype)
        
        # ë§ˆìŠ¤í¬ ì ìš©: ìœ íš¨í•œ í”½ì…€ë§Œ ì‚¬ìš©
        pred = pred[valid_mask]
        target = target[valid_mask]
        
        # ë¡œê·¸ ì°¨ì´ ê³„ì‚°: log(pred) - log(target)
        log_diff = torch.log(pred.clamp(min=self.eps)) - torch.log(target.clamp(min=self.eps))
        
        # SILog ì†ì‹¤ ê³„ì‚°: MSE - Î» * (í‰ê· )Â²
        loss = (log_diff ** 2).mean() - self.lambda_variance * (log_diff.mean() ** 2)
        return loss


class L1DepthLoss(nn.Module):
    """
    ìœ íš¨ ë§ˆìŠ¤í¬ ì²˜ë¦¬ê°€ í¬í•¨ëœ ê¹Šì´ ì¶”ì •ìš© L1 ì†ì‹¤ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    ì£¼ìš” íŠ¹ì§•:
    - L1 ì†ì‹¤: ì ˆëŒ€ ì˜¤ì°¨ì˜ í‰ê· ì„ ê³„ì‚°
    - ìœ íš¨ ë§ˆìŠ¤í¬ ì§€ì›: ìœ íš¨í•˜ì§€ ì•Šì€ í”½ì…€ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸
    - ìˆ˜ì¹˜ ì•ˆì •ì„±: ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ì˜¤ë¥˜ ë°©ì§€
    """
    def __init__(self, eps: float = 1e-6):
        """
        L1 ê¹Šì´ ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™”
        
        Args:
            eps: ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•œ ì‘ì€ ê°’ (ê¸°ë³¸ê°’: 1e-6)
        """
        super().__init__()
        self.eps = eps

    def forward(self, pred: torch.Tensor, target: torch.Tensor, mask: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        L1 ì†ì‹¤ ê³„ì‚°
        
        Args:
            pred: ì˜ˆì¸¡ëœ ê¹Šì´ ë§µ [B, 1, H, W]
            target: ì •ë‹µ ê¹Šì´ ë§µ [B, H, W] ë˜ëŠ” [B, 1, H, W]
            mask: ìœ íš¨ í”½ì…€ ë§ˆìŠ¤í¬ [B, H, W] ë˜ëŠ” [B, 1, H, W] (ì„ íƒì‚¬í•­)
            
        Returns:
            torch.Tensor: L1 ì†ì‹¤ ê°’
        """
        # ì°¨ì› ì •ê·œí™”: [B, 1, H, W] -> [B, H, W]
        if pred.dim() == 4 and pred.shape[1] == 1:
            pred = pred.squeeze(1)
        if target.dim() == 4 and target.shape[1] == 1:
            target = target.squeeze(1)
        
        # ìœ íš¨í•œ ê¹Šì´ ê°’ì— ëŒ€í•œ ë§ˆìŠ¤í¬ ìƒì„±
        if mask is None:
            valid_mask = (target > self.eps) & (torch.isfinite(target))
        else:
            if mask.dim() == 4 and mask.shape[1] == 1:
                mask = mask.squeeze(1)
            valid_mask = (target > self.eps) & (torch.isfinite(target)) & (mask > 0.5)
        
        # ìœ íš¨í•œ í”½ì…€ì´ ì—†ìœ¼ë©´ ì†ì‹¤ 0 ë°˜í™˜
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=pred.device, dtype=pred.dtype)
        
        # ìœ íš¨í•œ í”½ì…€ë§Œ ì‚¬ìš©í•˜ì—¬ L1 ì†ì‹¤ ê³„ì‚°
        pred = pred[valid_mask]
        target = target[valid_mask]
        return F.l1_loss(pred, target)


# ============================================================================
# ESANet ê¸°ë°˜ ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸
# ============================================================================
class ESANetMultiTask(nn.Module):
    """
    ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ ê¹Šì´ ì¶”ì •ì„ ìœ„í•œ ESANet ê¸°ë°˜ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ ëª¨ë¸ì…ë‹ˆë‹¤.
    
    ì•„í‚¤í…ì²˜:
        - ê³µìœ  ì¸ì½”ë”: ESANet ì¸ì½”ë” (RGB+Depth ë¶„ë¦¬ ì…ë ¥)
        - íƒœìŠ¤í¬ë³„ í—¤ë“œ: ì„¸ê·¸ë©˜í…Œì´ì…˜ í—¤ë“œ + ê¹Šì´ ì¶”ì • í—¤ë“œ
    
    ì£¼ìš” íŠ¹ì§•:
    - RGBì™€ Depthë¥¼ ë¶„ë¦¬ëœ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” íš¨ìœ¨ì ì¸ êµ¬ì¡°
    - ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë”© ì§€ì›
    - ì‘ì€ ë°°ì¹˜ í¬ê¸°ì— ëŒ€í•œ BatchNorm ìµœì í™”
    - 40ê°œ í´ë˜ìŠ¤ì—ì„œ 7ê°œ í´ë˜ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì–´ëŒ‘í„° í¬í•¨
    """
    def __init__(
        self,
        height: int = 480,
        width: int = 640,
        num_classes: int = 7,
        encoder_rgb: str = 'resnet34',
        encoder_depth: str = 'resnet34',
        encoder_block: str = 'NonBottleneck1D',
        pretrained_path: Optional[str] = None,
    ):
        """
        ESANet ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ì´ˆê¸°í™”
        
        Args:
            height: ì…ë ¥ ì´ë¯¸ì§€ ë†’ì´ (ê¸°ë³¸ê°’: 480)
            width: ì…ë ¥ ì´ë¯¸ì§€ ë„ˆë¹„ (ê¸°ë³¸ê°’: 640)
            num_classes: ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 7)
            encoder_rgb: RGB ì¸ì½”ë” ë°±ë³¸ (ê¸°ë³¸ê°’: 'resnet34')
            encoder_depth: Depth ì¸ì½”ë” ë°±ë³¸ (ê¸°ë³¸ê°’: 'resnet34')
            encoder_block: ì¸ì½”ë” ë¸”ë¡ íƒ€ì… (ê¸°ë³¸ê°’: 'NonBottleneck1D')
            pretrained_path: ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        super().__init__()
        
        if not ESANET_AVAILABLE:
            raise ImportError("ESANet ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ESANet ëª¨ë¸ ì´ˆê¸°í™” (RGB+Depth ë¶„ë¦¬ ì…ë ¥ìš©)
        # NYUv2 ê°€ì¤‘ì¹˜ì™€ í˜¸í™˜ë˜ë„ë¡ 40ê°œ í´ë˜ìŠ¤ë¡œ ì´ˆê¸°í™”
        self.esanet = ESANet(
            height=height,
            width=width,
            num_classes=40,  # NYUv2 ê°€ì¤‘ì¹˜ì™€ í˜¸í™˜ì„ ìœ„í•´ 40ê°œ í´ë˜ìŠ¤ë¡œ ì´ˆê¸°í™”
            encoder_rgb=encoder_rgb,
            encoder_depth=encoder_depth,
            encoder_block=encoder_block,
            pretrained_on_imagenet=False,  # ImageNet ì‚¬ì „ í•™ìŠµ ë¹„í™œì„±í™”
            activation='relu',
            encoder_decoder_fusion='add',
            context_module='ppm',
            fuse_depth_in_rgb_encoder='SE-add',
            upsampling='bilinear',
        )
        
        # ESANet ë‚´ë¶€ì˜ BatchNorm ì„¤ì • ë³€ê²½ (ë°°ì¹˜ í¬ê¸° 1 ë¬¸ì œ í•´ê²°)
        self._fix_batchnorm_for_small_batches()
        
        # ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ (ì„ íƒì‚¬í•­) - ì•ˆì „í•œ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
        if pretrained_path and os.path.exists(pretrained_path):
            print(f"ğŸ”„ Loading pretrained ESANet weights from {pretrained_path}")
            self._load_pretrained_weights_safe(pretrained_path)
        else:
            print("ğŸ“ No pretrained weights provided, training from scratch...")
        
        # 40ê°œ í´ë˜ìŠ¤ì—ì„œ 7ê°œ í´ë˜ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì–´ëŒ‘í„° ì¶”ê°€
        # 1x1 ì»¨ë³¼ë£¨ì…˜ìœ¼ë¡œ ì±„ë„ ìˆ˜ë§Œ ë³€ê²½
        self.class_adapter = nn.Conv2d(40, num_classes, 1)
        
        # ê¹Šì´ ì¶”ì • í—¤ë“œ: í–¥ìƒëœ CNN êµ¬ì¡° (ë‹¨ìˆœí™”ëœ ASPP ì ‘ê·¼ë²•)
        self.depth_head = nn.Sequential(
            # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ
            nn.Conv2d(40, 64, 3, padding=1),
            nn.BatchNorm2d(64, track_running_stats=False),
            nn.ReLU(inplace=True),
            
            # í™•ì¥ ì»¨ë³¼ë£¨ì…˜: ë” í° ìˆ˜ìš© ì˜ì—­ì„ ìœ„í•œ
            nn.Conv2d(64, 64, 3, padding=2, dilation=2),
            nn.BatchNorm2d(64, track_running_stats=False),
            nn.ReLU(inplace=True),
            
            # ìµœì¢… ê¹Šì´ ì˜ˆì¸¡
            nn.Conv2d(64, 32, 3, padding=1),
            nn.BatchNorm2d(32, track_running_stats=False),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 1, 1)  # 1ì±„ë„ ê¹Šì´ ë§µ ì¶œë ¥
        )
        
        print(f"ğŸ”§ ESANet Multi-Task Architecture:")
        print(f"  - Input: RGB [B,3,H,W] + Depth [B,1,H,W] (separated)")
        print(f"  - Output: Segmentation ({num_classes} classes) + Depth (1 channel)")
        print(f"  - Encoder RGB: {encoder_rgb}")
        print(f"  - Encoder Depth: {encoder_depth}")
    
    def _fix_batchnorm_for_small_batches(self):
        """
        ESANet ë‚´ë¶€ì˜ BatchNormì„ ì‘ì€ ë°°ì¹˜ í¬ê¸°ì— ë§ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤.
        
        ì‘ì€ ë°°ì¹˜ í¬ê¸°ì—ì„œ BatchNormì€ í†µê³„ëŸ‰ ì¶”ì •ì´ ë¶ˆì•ˆì •í•˜ë¯€ë¡œ
        GroupNormìœ¼ë¡œ êµì²´í•˜ì—¬ ì•ˆì •ì ì¸ í•™ìŠµì„ ë³´ì¥í•©ë‹ˆë‹¤.
        """
        def fix_batchnorm_recursive(module):
            for name, child in module.named_children():
                if isinstance(child, nn.BatchNorm2d):
                    # BatchNormì„ GroupNormìœ¼ë¡œ êµì²´ (ì±„ë„ ìˆ˜ì— ë”°ë¥¸ ë™ì  ê·¸ë£¹ ìˆ˜ ì„¤ì •)
                    num_channels = child.num_features
                    if num_channels >= 32:
                        num_groups = 32
                    elif num_channels >= 16:
                        num_groups = 16
                    elif num_channels >= 8:
                        num_groups = 8
                    else:
                        num_groups = max(1, num_channels // 2)  # ìµœì†Œ 2ì±„ë„ë‹¹ 1ê·¸ë£¹
                    
                    group_norm = nn.GroupNorm(num_groups=num_groups, num_channels=child.num_features, 
                                            eps=child.eps, affine=child.affine)
                    
                    # ê°€ì¤‘ì¹˜ì™€ ë°”ì´ì–´ìŠ¤ ë³µì‚¬
                    if child.affine:
                        group_norm.weight.data = child.weight.data.clone()
                        group_norm.bias.data = child.bias.data.clone()
                    
                    # ëª¨ë“ˆ êµì²´
                    setattr(module, name, group_norm)
                else:
                    fix_batchnorm_recursive(child)
        
        fix_batchnorm_recursive(self.esanet)
        # BatchNormì„ GroupNormìœ¼ë¡œ êµì²´ ì™„ë£Œ
    
    def _load_pretrained_weights_safe(self, pretrained_path: str):
        """
        ì•ˆì „í•œ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ - í˜¸í™˜ë˜ëŠ” ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            pretrained_path: ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # .pth íŒŒì¼ ì§ì ‘ ë¡œë“œ
            checkpoint = torch.load(pretrained_path, map_location='cpu')
            
            # ì²´í¬í¬ì¸íŠ¸ í‚¤ ë§¤í•‘ (ë‹¤ì–‘í•œ ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ ì§€ì›)
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            else:
                state_dict = checkpoint
            
            # í˜„ì¬ ëª¨ë¸ì˜ ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ê°€ì ¸ì˜¤ê¸°
            model_dict = self.esanet.state_dict()
            compatible_dict = {}
            
            # ì¡°ìš©íˆ ê°€ì¤‘ì¹˜ í˜¸í™˜ì„± í™•ì¸
            compatible_count = 0
            incompatible_count = 0
            
            for k, v in state_dict.items():
                if k in model_dict:
                    if v.shape == model_dict[k].shape:
                        compatible_dict[k] = v
                        compatible_count += 1
                    else:
                        # Shape mismatchëŠ” ì¡°ìš©íˆ ìŠ¤í‚µ
                        incompatible_count += 1
                else:
                    # Missing keyëŠ” ì¡°ìš©íˆ ìŠ¤í‚µ
                    incompatible_count += 1
            
            # í˜¸í™˜ë˜ëŠ” ê°€ì¤‘ì¹˜ë§Œ ë¡œë“œ
            if compatible_dict:
                model_dict.update(compatible_dict)
                self.esanet.load_state_dict(model_dict)
                print(f"âœ… Loaded {compatible_count} pretrained weights ({incompatible_count} skipped)")
            else:
                print("ğŸ“ No compatible weights found, training from scratch...")
                
        except FileNotFoundError:
            print(f"âš ï¸ Pretrained file not found: {pretrained_path}")
            print("ğŸ“ Training from scratch...")
        except RuntimeError as e:
            if "size mismatch" in str(e):
                print(f"âš ï¸ Model architecture mismatch: {e}")
                print("ğŸ“ Training from scratch...")
            else:
                raise  # ë‹¤ë¥¸ ëŸ°íƒ€ì„ ì—ëŸ¬ëŠ” ì¬ë°œìƒ
        except Exception as e:
            print(f"âš ï¸ Warning: Could not load pretrained weights: {e}")
            print("ğŸ“ Training from scratch...")
        
        
    def forward(self, rgb: torch.Tensor, depth: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ESANet ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ì˜ ìˆœì „íŒŒ ì—°ì‚°
        
        Args:
            rgb: RGB ì…ë ¥ í…ì„œ [B, 3, H, W]
            depth: ê¹Šì´ ì…ë ¥ í…ì„œ [B, 1, H, W]
        
        Returns:
            seg_logits: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§“ [B, num_classes, H, W]
            depth_pred: ê¹Šì´ ì˜ˆì¸¡ [B, 1, H, W] (0-1 ë²”ìœ„)
        """
        # ESANet ìˆœì „íŒŒ (40ê°œ í´ë˜ìŠ¤ ì¶œë ¥)
        esanet_output = self.esanet(rgb, depth)
        
        # ESANetì´ í›ˆë ¨ ëª¨ë“œì—ì„œ ì—¬ëŸ¬ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
        if isinstance(esanet_output, tuple):
            esanet_features = esanet_output[0]  # ì²« ë²ˆì§¸ ì¶œë ¥ì´ ë©”ì¸ segmentation ê²°ê³¼
        else:
            esanet_features = esanet_output
        
        # 40ê°œ í´ë˜ìŠ¤ì—ì„œ 7ê°œ í´ë˜ìŠ¤ë¡œ ë³€í™˜
        seg_logits = self.class_adapter(esanet_features)
        
        # ê¹Šì´ í—¤ë“œ ìˆœì „íŒŒ (40ê°œ í´ë˜ìŠ¤ íŠ¹ì§•ì—ì„œ)
        depth_raw = self.depth_head(esanet_features)
        
        # ì‹œê·¸ëª¨ì´ë“œ ì ìš©í•˜ì—¬ ê¹Šì´ë¥¼ [0, 1] ë²”ìœ„ë¡œ ì œí•œ
        depth_pred = torch.sigmoid(depth_raw)
        
        # ê¹Šì´ ì˜ˆì¸¡ì´ íƒ€ê²Ÿê³¼ ë™ì¼í•œ í˜•íƒœ [B, H, W]ê°€ ë˜ë„ë¡ ë³´ì¥
        if depth_pred.dim() == 4 and depth_pred.size(1) == 1:
            depth_pred = depth_pred.squeeze(1)
        
        return seg_logits, depth_pred


# ============================================================================
# ê¹Šì´ ì¶”ì • ë©”íŠ¸ë¦­
# ============================================================================
@torch.no_grad()
def compute_depth_metrics(pred: torch.Tensor, target: torch.Tensor, eps: float = 1e-6) -> Dict[str, torch.Tensor]:
    """
    í‘œì¤€ ê¹Šì´ ì¶”ì • ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        pred: ì˜ˆì¸¡ëœ ê¹Šì´ ë§µ [B, H, W]
        target: ì •ë‹µ ê¹Šì´ ë§µ [B, H, W]
        eps: ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•œ ì‘ì€ ê°’
        
    Returns:
        Dict[str, torch.Tensor]: ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ ê°’ì˜ ë”•ì…”ë„ˆë¦¬
            - abs_rel: ì ˆëŒ€ ìƒëŒ€ ì˜¤ì°¨
            - sq_rel: ì œê³± ìƒëŒ€ ì˜¤ì°¨
            - rmse: ì œê³±ê·¼ í‰ê·  ì œê³± ì˜¤ì°¨
            - rmse_log: ë¡œê·¸ ê³µê°„ì—ì„œì˜ RMSE
            - delta1, delta2, delta3: ì„ê³„ê°’ ë©”íŠ¸ë¦­
    """
    # ì°¨ì› ì •ê·œí™”: [B, 1, H, W] -> [B, H, W]
    if pred.dim() == 4 and pred.shape[1] == 1:
        pred = pred.squeeze(1)
    if target.dim() == 4 and target.shape[1] == 1:
        target = target.squeeze(1)
    
    # ìœ íš¨í•œ í”½ì…€ ë§ˆìŠ¤í¬ ìƒì„±
    valid_mask = (target > eps) & (torch.isfinite(target)) & (torch.isfinite(pred))
    if valid_mask.sum() == 0:
        # ìœ íš¨í•œ í”½ì…€ì´ ì—†ìœ¼ë©´ ëª¨ë“  ë©”íŠ¸ë¦­ì„ 0ìœ¼ë¡œ ë°˜í™˜
        return {
            "abs_rel": torch.tensor(0.0, device=pred.device),
            "sq_rel": torch.tensor(0.0, device=pred.device),
            "rmse": torch.tensor(0.0, device=pred.device),
            "rmse_log": torch.tensor(0.0, device=pred.device),
            "delta1": torch.tensor(0.0, device=pred.device),
            "delta2": torch.tensor(0.0, device=pred.device),
            "delta3": torch.tensor(0.0, device=pred.device),
        }
    
    # ìœ íš¨í•œ í”½ì…€ë§Œ ì‚¬ìš©
    pred = pred[valid_mask]
    target = target[valid_mask]
    
    # AbsRel: ì ˆëŒ€ ìƒëŒ€ ì˜¤ì°¨
    abs_rel = (torch.abs(pred - target) / (target + eps)).mean()

    # SqRel: ì œê³± ìƒëŒ€ ì˜¤ì°¨
    sq_rel = ((pred - target) ** 2 / (target + eps)).mean()

    # RMSE: ì œê³±ê·¼ í‰ê·  ì œê³± ì˜¤ì°¨
    rmse = torch.sqrt(((pred - target) ** 2).mean())
    
    # RMSE log: ë¡œê·¸ ê³µê°„ì—ì„œì˜ RMSE
    rmse_log = torch.sqrt(((torch.log(pred + eps) - torch.log(target + eps)) ** 2).mean())
    
    # ì„ê³„ê°’ ë©”íŠ¸ë¦­: ì •í™•ë„ ì„ê³„ê°’ (Î´ < 1.25, Î´ < 1.25Â², Î´ < 1.25Â³)
    ratio = torch.maximum(pred / (target + eps), target / (pred + eps))
    delta1 = (ratio < 1.25).float().mean()
    delta2 = (ratio < 1.25 ** 2).float().mean()
    delta3 = (ratio < 1.25 ** 3).float().mean()
    
    return {
        "abs_rel": abs_rel,
        "sq_rel": sq_rel,
        "rmse": rmse,
        "rmse_log": rmse_log,
        "delta1": delta1,
        "delta2": delta2,
        "delta3": delta3,
    }


# ============================================================================
# PyTorch Lightning ëª¨ë“ˆ
# ============================================================================
class LightningESANetMTL(pl.LightningModule):
    """
    ESANet ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì„ ìœ„í•œ PyTorch Lightning ëª¨ë“ˆì…ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ì†ì‹¤/ë©”íŠ¸ë¦­ ë¡œê¹…, ì²´í¬í¬ì¸íŠ¸, í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë£¨í”„ ê´€ë¦¬
    - ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜/DWA ë“± ë©€í‹°íƒœìŠ¤í¬ ì†ì‹¤ ê· í˜•í™” ì „ëµ ì§€ì›
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë©”íŠ¸ë¦­ ëˆ„ì  ë° ì‹œê°í™”
    - ìë™ ìµœì í™” ë° ìŠ¤ì¼€ì¤„ë§
    """
    def __init__(
        self,
        height: int = 480,
        width: int = 640,
        num_classes: int = 7,
        encoder_rgb: str = 'resnet34',
        encoder_depth: str = 'resnet34',
        encoder_block: str = 'NonBottleneck1D',
        lr: float = 1e-4,
        scheduler_t_max: int = 1000,
        final_lr: float = 1e-5,
        loss_type: str = "silog",  # "silog" or "l1"
        seg_loss_weight: float = 1.0,
        depth_loss_weight: float = 1.0,
        use_uncertainty_weighting: bool = False,
        use_dwa_weighting: bool = True,
        save_vis_dir: str = "",
        vis_max: int = 4,
        save_root_dir: str = "",
        pretrained_path: Optional[str] = None,
    ) -> None:
        """
        Lightning ESANet ë©€í‹°íƒœìŠ¤í¬ ëª¨ë“ˆ ì´ˆê¸°í™”
        
        Args:
            height: ì…ë ¥ ì´ë¯¸ì§€ ë†’ì´ (ê¸°ë³¸ê°’: 480)
            width: ì…ë ¥ ì´ë¯¸ì§€ ë„ˆë¹„ (ê¸°ë³¸ê°’: 640)
            num_classes: ì„¸ê·¸ë©˜í…Œì´ì…˜ í´ë˜ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 7)
            encoder_rgb: RGB ì¸ì½”ë” ë°±ë³¸ (ê¸°ë³¸ê°’: 'resnet34')
            encoder_depth: Depth ì¸ì½”ë” ë°±ë³¸ (ê¸°ë³¸ê°’: 'resnet34')
            encoder_block: ì¸ì½”ë” ë¸”ë¡ íƒ€ì… (ê¸°ë³¸ê°’: 'NonBottleneck1D')
            lr: í•™ìŠµë¥  (ê¸°ë³¸ê°’: 1e-4)
            scheduler_t_max: ìŠ¤ì¼€ì¤„ëŸ¬ ìµœëŒ€ ì—í­ (ê¸°ë³¸ê°’: 1000)
            loss_type: ê¹Šì´ ì†ì‹¤ í•¨ìˆ˜ íƒ€ì… (ê¸°ë³¸ê°’: "silog")
            seg_loss_weight: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì†ì‹¤ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 1.0)
            depth_loss_weight: ê¹Šì´ ì†ì‹¤ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 1.0)
            use_uncertainty_weighting: ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            use_dwa_weighting: DWA ê°€ì¤‘ì¹˜ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
            save_vis_dir: ì‹œê°í™” ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: "")
            vis_max: ìµœëŒ€ ì‹œê°í™” ê°œìˆ˜ (ê¸°ë³¸ê°’: 4)
            save_root_dir: ì €ì¥ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: "")
            pretrained_path: ì‚¬ì „í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        super().__init__()
        self.save_hyperparameters()
        
        # ESANet ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ì´ˆê¸°í™”
        self.model = ESANetMultiTask(
            height=height,
            width=width,
            num_classes=num_classes,
            encoder_rgb=encoder_rgb,
            encoder_depth=encoder_depth,
            encoder_block=encoder_block,
            pretrained_path=pretrained_path,
        )
        
        # ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
        # ì„¸ê·¸ë©˜í…Œì´ì…˜: Dice + Cross-Entropy ì¡°í•©ìœ¼ë¡œ ê°œì„ 
        try:
            import segmentation_models_pytorch as smp
            self.seg_dice_loss = smp.losses.DiceLoss(smp.losses.MULTICLASS_MODE, from_logits=True)
            self.seg_ce_loss = nn.CrossEntropyLoss()
            self._use_dice = True
        except Exception:
            # smp ë¯¸ì¡´ì¬ ì‹œ CEë§Œ ì‚¬ìš© (í›„ì† ì„¤ì¹˜ ê¶Œì¥)
            self.seg_ce_loss = nn.CrossEntropyLoss()
            self._use_dice = False
        
        # ê¹Šì´ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •
        if loss_type == "silog":
            self.depth_loss_fn = SILogLoss()
        else:
            self.depth_loss_fn = L1DepthLoss()
        
        # ì†ì‹¤ ê°€ì¤‘ì¹˜ ì „ëµ ì„¤ì •
        self.use_uncertainty_weighting = use_uncertainty_weighting
        self.use_dwa_weighting = use_dwa_weighting
        
        if use_uncertainty_weighting:
            # ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ê°€ì¤‘ì¹˜: í•™ìŠµ ê°€ëŠ¥í•œ ë¡œê·¸ ë¶„ì‚° íŒŒë¼ë¯¸í„°
            self.log_var_seg = nn.Parameter(torch.zeros(1))
            self.log_var_depth = nn.Parameter(torch.zeros(1))
        elif self.use_dwa_weighting:
            # DWA ì´ˆê¸°í™”: 2ê°œ íƒœìŠ¤í¬ (ì„¸ê·¸ë©˜í…Œì´ì…˜, ê¹Šì´)
            self.dwa = DynamicWeightAverage(num_tasks=2, temperature=2.0, window_size=10)
        else:
            # ìˆ˜ë™ ê°€ì¤‘ì¹˜ ì„¤ì •
            self.seg_loss_weight = seg_loss_weight
            self.depth_loss_weight = depth_loss_weight
        
        # ê¸°ë³¸ ì„¤ì • ì €ì¥
        self.num_classes = num_classes
        self.lr = lr
        self.t_max = scheduler_t_max
        self.final_lr = float(final_lr)
        self.base_vis_dir = save_vis_dir
        self.vis_max = int(vis_max) if vis_max is not None else 0
        self.save_root_dir = save_root_dir
        
        # ìµœê³  ì„±ëŠ¥ ì¶”ì ì€ ModelCheckpoint ì½œë°±ì—ì„œ ì²˜ë¦¬
        
        # í•™ìŠµ ê³¡ì„  ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.curves = {
            "train_loss": [],
            "val_loss": [],
            "train_seg_loss": [],
            "val_seg_loss": [],
            "train_depth_loss": [],
            "val_depth_loss": [],
            "train_miou": [],
            "val_miou": [],
            "train_abs_rel": [],
            "val_abs_rel": [],
            "train_sq_rel": [],
            "val_sq_rel": [],
            "train_rmse": [],
            "val_rmse": [],
            "train_rmse_log": [],
            "val_rmse_log": [],
            "val_delta1": [],
        }
        
        # ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë©”íŠ¸ë¦­ ëˆ„ì ê¸° (ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ì´ˆê¸°í™”)
        self._train_metrics_accumulator = None
        self._val_metrics_accumulator = None
        
        # ìˆ˜ë™ ê³„ì‚°ì„ ìœ„í•œ ì—í­ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”
        self._epoch_train_tp = None
        self._epoch_train_fp = None
        self._epoch_train_fn = None
        self._epoch_val_tp = None
        self._epoch_val_fp = None
        self._epoch_val_fn = None
        
        # ë©”íŠ¸ë¦­ ëˆ„ì ê¸°ëŠ” MetricsAccumulatorë¡œ ì²˜ë¦¬
        
        # íš¨ìœ¨ì ì¸ ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ìœ„í•œ torchmetrics ì„¤ì •
        if TORCHMETRICS_AVAILABLE:
            self.train_iou = JaccardIndex(task='multiclass', num_classes=num_classes, average='macro')
            self.val_iou = JaccardIndex(task='multiclass', num_classes=num_classes, average='macro')
            self.test_iou = JaccardIndex(task='multiclass', num_classes=num_classes, average='macro')
            self.train_mse = MeanSquaredError()
            self.val_mse = MeanSquaredError()
        else:
            # torchmetrics ë¯¸ì‚¬ìš© ì‹œ ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ í´ë°±
            self._epoch_train_tp = None
            self._epoch_train_fp = None
            self._epoch_train_fn = None
            self._epoch_val_tp = None
            self._epoch_val_fp = None
            self._epoch_val_fn = None
        
        # ì ì‘í˜• ì •ê·œí™”ë¥¼ ìœ„í•œ ìµœê³  ê°’ë“¤
        self.register_buffer("seg_best", torch.tensor(0.0))
        self.register_buffer("depth_best", torch.tensor(999.0))
        self.first_val_done = False
        # reset() í›„ compute() í˜¸ì¶œì„ í”¼í•˜ê¸° ìœ„í•œ ë§ˆì§€ë§‰ ì—í­ ë ˆë²¨ val iou ì €ì¥
        self._last_val_epoch_iou = None
        
        # ì‹œê°í™” íŒŒë¼ë¯¸í„° ì„¤ì •
        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]
        self.register_buffer("vis_mean", torch.tensor(mean).view(1, 3, 1, 1))
        self.register_buffer("vis_std", torch.tensor(std).view(1, 3, 1, 1))
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© ìƒ‰ìƒ íŒ”ë ˆíŠ¸
        self.register_buffer(
            "palette",
            torch.tensor([
                [0, 0, 0],       # 0 background (ê²€ì€ìƒ‰)
                [255, 255, 0],   # 1 chamoe (ë…¸ë€ìƒ‰)
                [255, 0, 0],     # 2 heatpipe (ë¹¨ê°„ìƒ‰)
                [0, 255, 0],     # 3 path (ì´ˆë¡ìƒ‰)
                [0, 0, 255],     # 4 pillar (íŒŒë€ìƒ‰)
                [255, 0, 255],   # 5 topdownfarm (ìí™ìƒ‰)
                [128, 128, 128], # 6 unknown (íšŒìƒ‰)
            ], dtype=torch.uint8)
        )
        # ê°„ë‹¨í•œ ì—í­ ì¢…ë£Œ ìš”ì•½ ì €ì¥ (ì½˜ì†” ì¶œë ¥ìš©)
        self.logged_metrics = {}
    
    def _compute_class_iou(self, tp, fp, fn, prefix=""):
        """
        ê³µí†µ IoU ê³„ì‚° í—¬í¼ í•¨ìˆ˜
        
        Args:
            tp: True Positive í…ì„œ [num_classes]
            fp: False Positive í…ì„œ [num_classes] 
            fn: False Negative í…ì„œ [num_classes]
            prefix: ë¡œê·¸ í‚¤ ì ‘ë‘ì‚¬ (ì˜ˆ: "val", "test")
        """
        class_names = [
            "background", "chamoe", "heatpipe", "path", "pillar", "topdownfarm", "unknown"
        ]
        for i, class_name in enumerate(class_names[: self.num_classes]):
            denom = (tp[i] + fp[i] + fn[i])
            iou_value = (tp[i] / denom) if denom > 0 else torch.tensor(0.0, device=tp.device)
            self.log(f"{prefix}_class_iou_{class_name}", iou_value, prog_bar=False, sync_dist=True)

    def forward(self, rgb: torch.Tensor, depth: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ëª¨ë¸ ìˆœì „íŒŒ
        
        Args:
            rgb: RGB ì…ë ¥ í…ì„œ [B, 3, H, W]
            depth: ê¹Šì´ ì…ë ¥ í…ì„œ [B, 1, H, W]
            
        Returns:
            seg_logits: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§“ [B, num_classes, H, W]
            depth_pred: ê¹Šì´ ì˜ˆì¸¡ [B, 1, H, W]
        """
        return self.model(rgb, depth)
    
    def _compute_loss(self, seg_logits: torch.Tensor, depth_pred: torch.Tensor,
                     seg_target: torch.Tensor, depth_target: torch.Tensor) -> Tuple[torch.Tensor, Dict]:
        """
        ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜ ë˜ëŠ” DWAë¥¼ ì‚¬ìš©í•œ ë©€í‹°íƒœìŠ¤í¬ ì†ì‹¤ ê³„ì‚°
        
        Args:
            seg_logits: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§“ [B, num_classes, H, W]
            depth_pred: ê¹Šì´ ì˜ˆì¸¡ [B, 1, H, W]
            seg_target: ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ê²Ÿ [B, H, W]
            depth_target: ê¹Šì´ íƒ€ê²Ÿ [B, H, W]
            
        Returns:
            total_loss: ì´ ì†ì‹¤ ê°’
            loss_dict: ì†ì‹¤ êµ¬ì„± ìš”ì†Œë“¤ì˜ ë”•ì…”ë„ˆë¦¬
        """
        
        # íƒœìŠ¤í¬ë³„ ì†ì‹¤ ê³„ì‚°
        if self._use_dice:
            # Dice + Cross-Entropy ì¡°í•© ì‚¬ìš©
            seg_dice = self.seg_dice_loss(seg_logits, seg_target)
            seg_ce = self.seg_ce_loss(seg_logits, seg_target)
            seg_loss = 0.7 * seg_dice + 0.3 * seg_ce
        else:
            # Cross-Entropyë§Œ ì‚¬ìš©
            seg_dice = None
            seg_ce = self.seg_ce_loss(seg_logits, seg_target)
            seg_loss = seg_ce
        depth_loss = self.depth_loss_fn(depth_pred, depth_target)
        
        if self.use_uncertainty_weighting:
            # Kendall et al. (CVPR 2018): Multi-Task Learning Using Uncertainty
            # L = (1/2Ïƒâ‚Â²)Lâ‚ + (1/2Ïƒâ‚‚Â²)Lâ‚‚ + log(Ïƒâ‚) + log(Ïƒâ‚‚)
            
            # ì•ˆì •ì„±ì„ ìœ„í•œ í´ë¨í•‘ (exp í­ë°œ ë°©ì§€)
            log_var_seg = torch.clamp(self.log_var_seg, min=-5.0, max=5.0)
            log_var_depth = torch.clamp(self.log_var_depth, min=-5.0, max=5.0)
            
            precision_seg = torch.exp(-log_var_seg)      # 1/ÏƒÂ²
            precision_depth = torch.exp(-log_var_depth)  # 1/ÏƒÂ²
            
            weighted_seg_loss = 0.5 * precision_seg * seg_loss + 0.5 * log_var_seg
            weighted_depth_loss = 0.5 * precision_depth * depth_loss + 0.5 * log_var_depth
            
            total_loss = weighted_seg_loss + weighted_depth_loss
            
        elif self.use_dwa_weighting:
            # Dynamic Weight Average (Liu et al., CVPR 2019)
            # ì†ì‹¤ ê°ì†Œìœ¨ ê¸°ë°˜ ìë™ ê°€ì¤‘ì¹˜ ì¡°ì •
            current_losses = [seg_loss.detach().item(), 
                            depth_loss.detach().item()]
            weights = self.dwa.update_weights(current_losses)
            
            weighted_seg_loss = weights[0] * seg_loss
            weighted_depth_loss = weights[1] * depth_loss
            total_loss = weighted_seg_loss + weighted_depth_loss
            
        else:
            # ìˆ˜ë™ ê°€ì¤‘ì¹˜: ê³ ì •ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©
            weighted_seg_loss = self.seg_loss_weight * seg_loss
            weighted_depth_loss = self.depth_loss_weight * depth_loss
            total_loss = weighted_seg_loss + weighted_depth_loss
        
        # ì†ì‹¤ êµ¬ì„± ìš”ì†Œë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì •ë¦¬
        loss_dict = {
            "total": total_loss,
            "seg": seg_loss,
            "seg_dice": seg_dice if seg_dice is not None else torch.tensor(0.0, device=seg_logits.device),
            "seg_ce": seg_ce,
            "depth": depth_loss,
            "weighted_seg": weighted_seg_loss,
            "weighted_depth": weighted_depth_loss,
        }
        
        # ê°€ì¤‘ì¹˜ ì „ëµë³„ ì¶”ê°€ ì •ë³´ ë¡œê¹…
        if self.use_uncertainty_weighting:
            loss_dict["log_var_seg"] = self.log_var_seg
            loss_dict["log_var_depth"] = self.log_var_depth
            # ì •ë°€ë„(ë¶ˆí™•ì‹¤ì„±) ê°’ë„ ë¡œê¹…
            loss_dict["precision_seg"] = torch.exp(-torch.clamp(self.log_var_seg, min=-5.0, max=5.0))
            loss_dict["precision_depth"] = torch.exp(-torch.clamp(self.log_var_depth, min=-5.0, max=5.0))
        elif self.use_dwa_weighting:
            # DWA ê°€ì¤‘ì¹˜ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ë¡œê¹…
            weights = self.dwa.get_weights()
            loss_dict["dwa_weight_seg"] = weights[0]
            loss_dict["dwa_weight_depth"] = weights[1]
        
        return total_loss, loss_dict

    @torch.no_grad()
    def _compute_metrics(self, seg_logits: torch.Tensor, depth_pred: torch.Tensor,
                        seg_target: torch.Tensor, depth_target: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        torchmetricsë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ íƒœìŠ¤í¬ì˜ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        
        Args:
            seg_logits: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¡œì§“ [B, num_classes, H, W]
            depth_pred: ê¹Šì´ ì˜ˆì¸¡ [B, 1, H, W]
            seg_target: ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ê²Ÿ [B, H, W]
            depth_target: ê¹Šì´ íƒ€ê²Ÿ [B, H, W]
            
        Returns:
            Dict[str, torch.Tensor]: ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ ê°’ì˜ ë”•ì…”ë„ˆë¦¬
        """
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë©”íŠ¸ë¦­ ê³„ì‚°
        prob = torch.softmax(seg_logits, dim=1)
        seg_pred = torch.argmax(prob, dim=1)
        
        # ê°„ë‹¨í•œ ì •í™•ë„ ê³„ì‚°
        correct = (seg_pred == seg_target).float()
        seg_acc = correct.mean()
        
        # ê¹Šì´ ë©”íŠ¸ë¦­ (í•­ìƒ ê³„ì‚°)
        depth_metrics = compute_depth_metrics(depth_pred, depth_target)
        
        if TORCHMETRICS_AVAILABLE:
            # torchmetricsë¥¼ ì‚¬ìš©í•œ íš¨ìœ¨ì ì¸ ê³„ì‚°
            # ì˜ˆì¸¡ê³¼ ë™ì¼í•œ ë””ë°”ì´ìŠ¤ë¡œ ë©”íŠ¸ë¦­ ì´ë™
            if seg_pred.device != next(self.parameters()).device:
                seg_pred = seg_pred.to(next(self.parameters()).device)
                seg_target = seg_target.to(next(self.parameters()).device)
                depth_pred = depth_pred.to(next(self.parameters()).device)
                depth_target = depth_target.to(next(self.parameters()).device)
            
            # torchmetricsë¥¼ ì‚¬ìš©í•œ IoU ê³„ì‚°
            miou = self.train_iou(seg_pred, seg_target) if self.training else self.val_iou(seg_pred, seg_target)
            
            # ê¹Šì´ì— ëŒ€í•œ MSE ê³„ì‚°
            mse = self.train_mse(depth_pred, depth_target) if self.training else self.val_mse(depth_pred, depth_target)
            
            metrics = {
                "miou": miou,
                "seg_acc": seg_acc,
                "mse": mse,
                "abs_rel": depth_metrics["abs_rel"],
                "sq_rel": depth_metrics["sq_rel"],
                "rmse": depth_metrics["rmse"],
                "rmse_log": depth_metrics["rmse_log"],
                "delta1": depth_metrics["delta1"],
                "delta2": depth_metrics["delta2"],
                "delta3": depth_metrics["delta3"],
            }
        else:
            # ìˆ˜ë™ ê³„ì‚°ìœ¼ë¡œ í´ë°±
            # í´ë˜ìŠ¤ë³„ IoU ê³„ì‚°
            tp = torch.zeros(self.num_classes, device=seg_pred.device)
            fp = torch.zeros(self.num_classes, device=seg_pred.device)
            fn = torch.zeros(self.num_classes, device=seg_pred.device)
            
            for c in range(self.num_classes):
                tp[c] = ((seg_pred == c) & (seg_target == c)).float().sum()
                fp[c] = ((seg_pred == c) & (seg_target != c)).float().sum()
                fn[c] = ((seg_pred != c) & (seg_target == c)).float().sum()
            
            # IoU ê³„ì‚°
            iou = tp / (tp + fp + fn + 1e-8)
            miou = iou.mean()
            
            metrics = {
                "miou": miou,
                "seg_acc": seg_acc,
                "abs_rel": depth_metrics["abs_rel"],
                "sq_rel": depth_metrics["sq_rel"],
                "rmse": depth_metrics["rmse"],
                "rmse_log": depth_metrics["rmse_log"],
                "delta1": depth_metrics["delta1"],
                "delta2": depth_metrics["delta2"],
                "delta3": depth_metrics["delta3"],
            }
        
        return metrics

    def training_step(self, batch, batch_idx):
        """
        í•™ìŠµ ìŠ¤í…: ìˆœì „íŒŒ, ì†ì‹¤ ê³„ì‚°, ë©”íŠ¸ë¦­ ê³„ì‚°, ë¡œê¹…
        
        Args:
            batch: ë°°ì¹˜ ë°ì´í„° (rgb, depth, seg_masks, depth_target, filenames)
            batch_idx: ë°°ì¹˜ ì¸ë±ìŠ¤
            
        Returns:
            torch.Tensor: ì´ ì†ì‹¤ ê°’
        """
        rgb, depth, seg_masks, depth_target = batch[:4]
        seg_logits, depth_pred = self(rgb, depth)
        
        total_loss, loss_dict = self._compute_loss(seg_logits, depth_pred, seg_masks, depth_target)
        metrics = self._compute_metrics(seg_logits.detach(), depth_pred.detach(), seg_masks, depth_target)
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        self.log("train_loss", total_loss, prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("train_seg_loss", loss_dict["seg"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        if self._use_dice:
            self.log("train_seg_dice", loss_dict["seg_dice"], prog_bar=False, sync_dist=True)
        self.log("train_seg_ce", loss_dict["seg_ce"], prog_bar=False, sync_dist=True)
        self.log("train_depth_loss", loss_dict["depth"], prog_bar=False, sync_dist=True)
        self.log("train_weighted_seg", loss_dict["weighted_seg"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        self.log("train_weighted_depth", loss_dict["weighted_depth"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        self.log("train_rmse", metrics["rmse"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        # train_miouëŠ” ì œê±° - train_epoch_iouê°€ ì •í™•í•œ ê°’
        self.log("train_abs_rel", metrics["abs_rel"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        
        
        # ë¶ˆí™•ì‹¤ì„± ê°€ì¤‘ì¹˜ ë¡œê¹…
        if self.use_uncertainty_weighting:
            self.log("log_var_seg", loss_dict["log_var_seg"], prog_bar=False, sync_dist=True)
            self.log("log_var_depth", loss_dict["log_var_depth"], prog_bar=False, sync_dist=True)
            self.log("train_weighted_seg", loss_dict["weighted_seg"], prog_bar=True, sync_dist=True)
            self.log("train_weighted_depth", loss_dict["weighted_depth"], prog_bar=True, sync_dist=True)
        
        # ì—í­ ë ˆë²¨ IoU ê³„ì‚°ì„ ìœ„í•œ í´ë˜ìŠ¤ë³„ í†µê³„ ëˆ„ì 
        seg_pred = torch.argmax(torch.softmax(seg_logits.detach(), dim=1), dim=1)
        
        # ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ì˜¬ë°”ë¥¸ ë””ë°”ì´ìŠ¤ì— ëˆ„ì ê¸° ì´ˆê¸°í™”
        if self._epoch_train_tp is None:
            device = seg_pred.device
            self._epoch_train_tp = torch.zeros(self.num_classes, device=device)
            self._epoch_train_fp = torch.zeros(self.num_classes, device=device)
            self._epoch_train_fn = torch.zeros(self.num_classes, device=device)
        
        # í´ë˜ìŠ¤ë³„ True Positive, False Positive, False Negative ê³„ì‚°
        for c in range(self.num_classes):
            tp = ((seg_pred == c) & (seg_masks == c)).float().sum()
            fp = ((seg_pred == c) & (seg_masks != c)).float().sum()
            fn = ((seg_pred != c) & (seg_masks == c)).float().sum()
            self._epoch_train_tp[c] += tp
            self._epoch_train_fp[c] += fp
            self._epoch_train_fn[c] += fn

        # ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ë©”íŠ¸ë¦­ ëˆ„ì ê¸° ì´ˆê¸°í™”
        if self._train_metrics_accumulator is None:
            self._train_metrics_accumulator = MetricsAccumulator(device=total_loss.device)
        
        # ë©”íŠ¸ë¦­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥ (GPUì—ì„œ ìœ ì§€)
        metrics_to_store = {
            "loss": total_loss,
            "seg_loss": loss_dict["seg"],
            "seg_ce": loss_dict["seg_ce"],
            "depth_loss": loss_dict["depth"],
            "miou": metrics["miou"],
            "abs_rel": metrics["abs_rel"],
            "sq_rel": metrics["sq_rel"],
            "rmse": metrics["rmse"],
            "rmse_log": metrics["rmse_log"],
        }
        
        # Dice ì†ì‹¤ì´ ì‚¬ìš©ë˜ëŠ” ê²½ìš° ì¶”ê°€
        if self._use_dice and "seg_dice" in loss_dict:
            metrics_to_store["seg_dice"] = loss_dict["seg_dice"]
        
        self._train_metrics_accumulator.update(**metrics_to_store)
        
        return total_loss

    def validation_step(self, batch, batch_idx):
        rgb, depth, seg_masks, depth_target = batch[:4]
        
        # Measure inference time
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        t0 = time.perf_counter()
        seg_logits, depth_pred = self(rgb, depth)
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        dt = max(1e-9, time.perf_counter() - t0)
        
        total_loss, loss_dict = self._compute_loss(seg_logits, depth_pred, seg_masks, depth_target)
        metrics = self._compute_metrics(seg_logits.detach(), depth_pred.detach(), seg_masks, depth_target)
        
        # FPS - ë‹¨ì¼ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        per_image_time = dt / rgb.shape[0]
        fps = 1.0 / per_image_time
        
        # Logging
        self.log("val_loss", total_loss, prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_seg_loss", loss_dict["seg"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        if self._use_dice:
            self.log("val_seg_dice", loss_dict["seg_dice"], prog_bar=False, sync_dist=True)
        self.log("val_seg_ce", loss_dict["seg_ce"], prog_bar=False, sync_dist=True)
        self.log("val_depth_loss", loss_dict["depth"], prog_bar=True, sync_dist=True)
        self.log("val_weighted_seg", loss_dict["weighted_seg"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_weighted_depth", loss_dict["weighted_depth"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        # val_miouëŠ” ì œê±° - val_epoch_iouê°€ ì •í™•í•œ ê°’
        self.log("val_abs_rel", metrics["abs_rel"], prog_bar=True, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_sq_rel", metrics["sq_rel"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_rmse", metrics["rmse"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_rmse_log", metrics["rmse_log"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_delta1", metrics["delta1"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_delta2", metrics["delta2"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_delta3", metrics["delta3"], prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        self.log("val_fps", fps, prog_bar=False, sync_dist=True, batch_size=rgb.shape[0])
        
        if self.use_uncertainty_weighting:
            self.log("val_log_var_seg", loss_dict["log_var_seg"], prog_bar=False, sync_dist=True)
            self.log("val_log_var_depth", loss_dict["log_var_depth"], prog_bar=False, sync_dist=True)
        
        # torchmetricsë¥¼ ì‚¬ìš©í•œ IoU ì—…ë°ì´íŠ¸ (ëˆ„ì ë§Œ, ë¡œê¹… ì•ˆí•¨)
        if TORCHMETRICS_AVAILABLE:
            seg_pred = torch.argmax(torch.softmax(seg_logits.detach(), dim=1), dim=1)
            self.val_iou(seg_pred, seg_masks)
        
        # No validation-stage visual saving
        
        # Accumulate class-wise statistics for epoch-level IoU calculation
        seg_pred = torch.argmax(torch.softmax(seg_logits.detach(), dim=1), dim=1)
        
        # Initialize accumulators on correct device if first time
        if self._epoch_val_tp is None:
            device = seg_pred.device
            self._epoch_val_tp = torch.zeros(self.num_classes, device=device)
            self._epoch_val_fp = torch.zeros(self.num_classes, device=device)
            self._epoch_val_fn = torch.zeros(self.num_classes, device=device)
        
        for c in range(self.num_classes):
            tp = ((seg_pred == c) & (seg_masks == c)).float().sum()
            fp = ((seg_pred == c) & (seg_masks != c)).float().sum()
            fn = ((seg_pred != c) & (seg_masks == c)).float().sum()
            self._epoch_val_tp[c] += tp
            self._epoch_val_fp[c] += fp
            self._epoch_val_fn[c] += fn

        # Combined metric for balanced early stopping
        if not self.first_val_done:
            self.seg_best = metrics["miou"].clone()
            self.depth_best = metrics["abs_rel"].clone()
            self.first_val_done = True
        
        self.seg_best = torch.maximum(self.seg_best, metrics["miou"])
        self.depth_best = torch.minimum(self.depth_best, metrics["abs_rel"])
        
        seg_normalized = 1.0 - (metrics["miou"] / (self.seg_best + 1e-6))
        depth_normalized = metrics["abs_rel"] / (self.depth_best + 1e-6)
        combined_metric = 0.5 * seg_normalized + 0.5 * depth_normalized
        
        self.log("val_combined_metric", combined_metric, prog_bar=True, sync_dist=True)
        
        # Store for epoch summary logging
        self.logged_metrics["val_loss"] = total_loss
        self.logged_metrics["val_abs_rel"] = metrics["abs_rel"]
        
        # ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ë©”íŠ¸ë¦­ ëˆ„ì ê¸° ì´ˆê¸°í™”
        if self._val_metrics_accumulator is None:
            self._val_metrics_accumulator = MetricsAccumulator(device=total_loss.device)
        
        # ë©”íŠ¸ë¦­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥ (GPUì—ì„œ ìœ ì§€)
        metrics_to_store = {
            "loss": total_loss,
            "seg_loss": loss_dict["seg"],
            "seg_ce": loss_dict["seg_ce"],
            "depth_loss": loss_dict["depth"],
            "miou": metrics["miou"],
            "abs_rel": metrics["abs_rel"],
            "sq_rel": metrics["sq_rel"],
            "rmse": metrics["rmse"],
            "rmse_log": metrics["rmse_log"],
            "delta1": metrics["delta1"],
            "delta2": metrics["delta2"],
            "delta3": metrics["delta3"],
        }
        
        # Dice ì†ì‹¤ì´ ì‚¬ìš©ë˜ëŠ” ê²½ìš° ì¶”ê°€
        if self._use_dice and "seg_dice" in loss_dict:
            metrics_to_store["seg_dice"] = loss_dict["seg_dice"]
        
        self._val_metrics_accumulator.update(**metrics_to_store)
        
        return total_loss

    def test_step(self, batch, batch_idx):
        rgb, depth, seg_masks, depth_target = batch[:4]
        filenames = None
        if isinstance(batch, (list, tuple)) and len(batch) >= 5:
            filenames = batch[4]
        
        # Measure inference time
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        t0 = time.perf_counter()
        seg_logits, depth_pred = self(rgb, depth)
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        dt = max(1e-9, time.perf_counter() - t0)
        
        total_loss, loss_dict = self._compute_loss(seg_logits, depth_pred, seg_masks, depth_target)
        metrics = self._compute_metrics(seg_logits.detach(), depth_pred.detach(), seg_masks, depth_target)
        
        # FPS - ë‹¨ì¼ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
        per_image_time = dt / rgb.shape[0]
        fps = 1.0 / per_image_time
        
        # Logging
        self.log("test_loss", total_loss, sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_seg_loss", loss_dict["seg"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_depth_loss", loss_dict["depth"], sync_dist=True, batch_size=rgb.shape[0])
        # test_miouëŠ” ì œê±° - test_epoch_iouê°€ ì •í™•í•œ ê°’
        self.log("test_abs_rel", metrics["abs_rel"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_sq_rel", metrics["sq_rel"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_rmse", metrics["rmse"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_rmse_log", metrics["rmse_log"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_delta1", metrics["delta1"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_delta2", metrics["delta2"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_delta3", metrics["delta3"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_acc", metrics["seg_acc"], sync_dist=True, batch_size=rgb.shape[0])
        self.log("test_fps", fps, sync_dist=True, batch_size=rgb.shape[0])
        
        if self.use_uncertainty_weighting:
            self.log("test_log_var_seg", loss_dict["log_var_seg"], sync_dist=True)
            self.log("test_log_var_depth", loss_dict["log_var_depth"], sync_dist=True)
        
        # torchmetricsë¥¼ ì‚¬ìš©í•œ IoU ì—…ë°ì´íŠ¸ (ëˆ„ì ë§Œ, ë¡œê¹… ì•ˆí•¨)
        if TORCHMETRICS_AVAILABLE:
            seg_pred = torch.argmax(torch.softmax(seg_logits.detach(), dim=1), dim=1)
            self.test_iou(seg_pred, seg_masks)
        
        # í´ë˜ìŠ¤ë³„ IoU ì§‘ê³„ë¥¼ ìœ„í•œ í†µê³„ ëˆ„ì  (í…ŒìŠ¤íŠ¸ ì—í­ ë ˆë²¨)
        seg_pred = torch.argmax(torch.softmax(seg_logits.detach(), dim=1), dim=1)
        if not hasattr(self, "_epoch_test_tp") or self._epoch_test_tp is None:
            device = seg_pred.device
            self._epoch_test_tp = torch.zeros(self.num_classes, device=device)
            self._epoch_test_fp = torch.zeros(self.num_classes, device=device)
            self._epoch_test_fn = torch.zeros(self.num_classes, device=device)
        for c in range(self.num_classes):
            tp = ((seg_pred == c) & (seg_masks == c)).float().sum()
            fp = ((seg_pred == c) & (seg_masks != c)).float().sum()
            fn = ((seg_pred != c) & (seg_masks == c)).float().sum()
            self._epoch_test_tp[c] += tp
            self._epoch_test_fp[c] += fp
            self._epoch_test_fn[c] += fn
        
        # Save visuals for test: save for ALL batches (full dataset inference)
        self._maybe_save_visuals(rgb, depth, seg_masks, depth_target, seg_logits, depth_pred,
                                stage="test", batch_idx=batch_idx, filenames=filenames)
        
        return total_loss

    def on_test_epoch_end(self) -> None:
        """í…ŒìŠ¤íŠ¸ ì—í­ ì¢…ë£Œ ì‹œ ì •í™•í•œ ì—í­ë³„ mIoU ë° í´ë˜ìŠ¤ë³„ IoU ê³„ì‚°"""
        # torchmetricsë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ mIoU ê³„ì‚°
        if TORCHMETRICS_AVAILABLE:
            epoch_iou = self.test_iou.compute()
            self.log("test_miou", epoch_iou, prog_bar=True, sync_dist=True)
            self.test_iou.reset()
        
        # í´ë˜ìŠ¤ë³„ IoU ê³„ì‚° ë° ë¡œê¹…
        if hasattr(self, "_epoch_test_tp") and self._epoch_test_tp is not None:
            self._compute_class_iou(self._epoch_test_tp, self._epoch_test_fp, self._epoch_test_fn, "test")
            
            # Reset accumulators
            self._epoch_test_tp = None
            self._epoch_test_fp = None
            self._epoch_test_fn = None

    def on_train_epoch_end(self) -> None:
        # Use memory-efficient metrics accumulator
        if self._train_metrics_accumulator is not None:
            epoch_metrics = self._train_metrics_accumulator.compute_mean()
            
            # Update curves
            for key, value in epoch_metrics.items():
                curve_key = f"train_{key}"
                if curve_key in self.curves:
                    self.curves[curve_key].append(value)
            
            # Reset accumulator for next epoch
            self._train_metrics_accumulator.reset()
        
        # Log epoch-level metrics using torchmetrics
        if TORCHMETRICS_AVAILABLE:
            # Compute epoch-level IoU (ì •í™•í•œ ì—í­ í‰ê· )
            epoch_iou = self.train_iou.compute()
            self.log("train_miou", epoch_iou, prog_bar=True, sync_dist=True)
            self.train_iou.reset()
            
            # Compute epoch-level MSE
            epoch_mse = self.train_mse.compute()
            self.log("train_epoch_mse", epoch_mse, prog_bar=False, sync_dist=True)
            self.train_mse.reset()
        else:
            # Fallback to manual computation
            if self._epoch_train_tp is not None:
                class_names = [
                    "background", "chamoe", "heatpipe", "path", "pillar", "topdownfarm", "unknown"
                ]
                for i, class_name in enumerate(class_names[: self.num_classes]):
                    denom = (self._epoch_train_tp[i] + self._epoch_train_fp[i] + self._epoch_train_fn[i])
                    iou_value = (self._epoch_train_tp[i] / denom) if denom > 0 else torch.tensor(0.0)
                    self.log(f"train_class_iou_{class_name}", iou_value, prog_bar=False, sync_dist=True)

        # Reset accumulators
        if self._epoch_train_tp is not None:
            self._epoch_train_tp.zero_()
            self._epoch_train_fp.zero_()
            self._epoch_train_fn.zero_()

    def on_validation_epoch_end(self) -> None:
        # Use memory-efficient metrics accumulator
        if self._val_metrics_accumulator is not None:
            epoch_metrics = self._val_metrics_accumulator.compute_mean()
            
            # Update curves
            for key, value in epoch_metrics.items():
                curve_key = f"val_{key}"
                if curve_key in self.curves:
                    self.curves[curve_key].append(value)
            
            # Reset accumulator for next epoch
            self._val_metrics_accumulator.reset()
        
        # Log epoch-level metrics using torchmetrics
        if TORCHMETRICS_AVAILABLE:
            # Compute epoch-level IoU (ì •í™•í•œ ì—í­ í‰ê· )
            epoch_iou = self.val_iou.compute()
            self.log("val_miou", epoch_iou, prog_bar=True, sync_dist=True)
            # cache for summary print
            try:
                self._last_val_epoch_iou = float(epoch_iou.detach().cpu().item())
            except Exception:
                self._last_val_epoch_iou = None
            self.val_iou.reset()
            
            # Compute epoch-level MSE
            epoch_mse = self.val_mse.compute()
            self.log("val_epoch_mse", epoch_mse, prog_bar=False, sync_dist=True)
            self.val_mse.reset()
        
        # í´ë˜ìŠ¤ë³„ IoU ê³„ì‚° ë° ë¡œê¹… (torchmetrics ì‚¬ìš© ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´)
        if self._epoch_val_tp is not None:
            self._compute_class_iou(self._epoch_val_tp, self._epoch_val_fp, self._epoch_val_fn, "val")

        
        # ë¡œê·¸ ì¶œë ¥ì€ CustomEarlyStopping ì½œë°±ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤

        # Reset accumulators
        if self._epoch_val_tp is not None:
            self._epoch_val_tp.zero_()
            self._epoch_val_fp.zero_()
            self._epoch_val_fn.zero_()

    def on_fit_end(self) -> None:
        """Save final visualizations and curves at the end of training"""
        try:
            # Final-stage visual saving disabled (keep only test-stage visuals)
            
            # Save curves
            if not self.save_root_dir:
                return
            curves_dir = os.path.join(self.save_root_dir, "curves")
            os.makedirs(curves_dir, exist_ok=True)

            # Loss curves
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            
            # Total loss
            ax = axes[0, 0]
            if len(self.curves["train_loss"]) > 0:
                ax.plot(self.curves["train_loss"], label="train")
            if len(self.curves["val_loss"]) > 0:
                ax.plot(self.curves["val_loss"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("Total Loss")
            ax.grid(True)
            ax.legend()
            
            # Segmentation loss
            ax = axes[0, 1]
            if len(self.curves["train_seg_loss"]) > 0:
                ax.plot(self.curves["train_seg_loss"], label="train")
            if len(self.curves["val_seg_loss"]) > 0:
                ax.plot(self.curves["val_seg_loss"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("Segmentation Loss")
            ax.grid(True)
            ax.legend()
            
            # Depth loss
            ax = axes[1, 0]
            if len(self.curves["train_depth_loss"]) > 0:
                ax.plot(self.curves["train_depth_loss"], label="train")
            if len(self.curves["val_depth_loss"]) > 0:
                ax.plot(self.curves["val_depth_loss"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("Depth Loss")
            ax.grid(True)
            ax.legend()
            
            # mIoU
            ax = axes[1, 1]
            if len(self.curves["train_miou"]) > 0:
                ax.plot(self.curves["train_miou"], label="train")
            if len(self.curves["val_miou"]) > 0:
                ax.plot(self.curves["val_miou"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("mIoU")
            ax.grid(True)
            ax.legend()
            
            plt.tight_layout()
            plt.savefig(os.path.join(curves_dir, "loss_curves.png"))
            plt.close()
            
            # Depth metrics
            fig, axes = plt.subplots(1, 3, figsize=(15, 4))
            
            # AbsRel
            ax = axes[0]
            if len(self.curves["train_abs_rel"]) > 0:
                ax.plot(self.curves["train_abs_rel"], label="train")
            if len(self.curves["val_abs_rel"]) > 0:
                ax.plot(self.curves["val_abs_rel"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("AbsRel (lower is better)")
            ax.set_yscale("log")
            ax.grid(True)
            ax.legend()
            
            # RMSE
            ax = axes[1]
            if len(self.curves["train_rmse"]) > 0:
                ax.plot(self.curves["train_rmse"], label="train")
            if len(self.curves["val_rmse"]) > 0:
                ax.plot(self.curves["val_rmse"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("RMSE (lower is better)")
            ax.grid(True)
            ax.legend()
            
            # Î´<1.25
            ax = axes[2]
            if len(self.curves["val_delta1"]) > 0:
                ax.plot(self.curves["val_delta1"], label="val")
            ax.set_xlabel("epoch")
            ax.set_ylabel("Î´<1.25 (higher is better)")
            ax.grid(True)
            ax.legend()
            
            plt.tight_layout()
            plt.savefig(os.path.join(curves_dir, "depth_metrics.png"))
            plt.close()
            
        except Exception as e:
            warnings.warn(f"Failed to save curves: {e}")

    @torch.no_grad()
    def _maybe_save_visuals(self, rgb: torch.Tensor, depth: torch.Tensor, seg_masks: torch.Tensor, 
                           depth_target: torch.Tensor, seg_logits: torch.Tensor, 
                           depth_pred: torch.Tensor, stage: str, batch_idx: int,
                           filenames: Optional[List[str]] = None) -> None:
        if not self.base_vis_dir or self.vis_max <= 0:
            return
        # For test stage, allow saving for all batches. For others, only first batch.
        if stage != "test" and batch_idx != 0:
            return
        
        try:
            import os
            from PIL import Image as PILImage
            os.makedirs(os.path.join(self.base_vis_dir, stage), exist_ok=True)

            # Denormalize RGB images (keep on GPU for torchvision processing)
            imgs = (rgb * self.vis_std + self.vis_mean).clamp(0, 1)
            imgs = (imgs * 255.0).to(torch.uint8)

            # Segmentation predictions (keep on GPU for torchvision processing)
            seg_preds = torch.softmax(seg_logits, dim=1).argmax(dim=1).to(torch.int64)
            seg_gts = seg_masks.to(torch.int64)
            
            # Depth predictions and targets (keep on GPU for torchvision processing)
            depth_preds = depth_pred.squeeze(1)
            depth_gts = depth_target

            pal = self.palette.cpu()
            
            def colorize_seg(label_hw: torch.Tensor) -> np.ndarray:
                # Ensure CPU numpy array
                label_np = label_hw.detach().cpu().numpy()
                h, w = label_np.shape
                out = np.zeros((h, w, 3), dtype=np.uint8)
                for c in range(min(self.num_classes, pal.shape[0])):
                    out[label_np == c] = pal[c].numpy()
                return out
            
            def colorize_depth(depth_hw: torch.Tensor) -> np.ndarray:
                """Colorize depth with viridis colormap (pure numpy implementation)"""
                depth_np = depth_hw.detach().cpu().numpy()
                depth_norm = (depth_np - depth_np.min()) / (depth_np.max() - depth_np.min() + 1e-8)
                
                # Pure numpy viridis colormap implementation
                # Viridis colormap: blue -> green -> yellow
                depth_colored = np.zeros((*depth_norm.shape, 3), dtype=np.uint8)
                
                # Blue to green transition (0.0 to 0.5)
                mask1 = depth_norm <= 0.5
                if mask1.any():
                    t = depth_norm[mask1] * 2.0  # 0 to 1
                    depth_colored[mask1, 0] = (68 * (1 - t) + 34 * t).astype(np.uint8)  # Blue to green
                    depth_colored[mask1, 1] = (1 * (1 - t) + 139 * t).astype(np.uint8)  # Blue to green
                    depth_colored[mask1, 2] = (84 * (1 - t) + 34 * t).astype(np.uint8)   # Blue to green
                
                # Green to yellow transition (0.5 to 1.0)
                mask2 = depth_norm > 0.5
                if mask2.any():
                    t = (depth_norm[mask2] - 0.5) * 2.0  # 0 to 1
                    depth_colored[mask2, 0] = (34 * (1 - t) + 253 * t).astype(np.uint8)  # Green to yellow
                    depth_colored[mask2, 1] = (139 * (1 - t) + 231 * t).astype(np.uint8) # Green to yellow
                    depth_colored[mask2, 2] = (34 * (1 - t) + 37 * t).astype(np.uint8)   # Green to yellow
                
                return depth_colored

            # For test stage, save all images in the batch; otherwise respect vis_max
            save_count = imgs.shape[0] if stage == "test" else min(self.vis_max, imgs.shape[0])
            
            # Use unified PIL-based visualization
            self._save_visuals_pil(imgs, seg_gts, seg_preds, depth_gts, depth_preds, 
                                 stage, save_count, filenames, colorize_seg, colorize_depth)
        except Exception as e:
            warnings.warn(f"Failed to save visualization: {e}")
    
    def _save_visuals_pil(self, imgs, seg_gts, seg_preds, depth_gts, depth_preds, 
                         stage, save_count, filenames, colorize_seg, colorize_depth):
        """Fallback PIL-based visualization"""
        try:
            for i in range(save_count):
                # Move to CPU before numpy conversion
                img = imgs[i].detach().cpu().permute(1, 2, 0).numpy()
                
                # Segmentation results
                seg_gt = colorize_seg(seg_gts[i])
                seg_pr = colorize_seg(seg_preds[i])
                
                # Depth results
                depth_gt = colorize_depth(depth_gts[i])
                depth_pr = colorize_depth(depth_preds[i])
                
                # Resize depth to match image size if needed
                if depth_gt.shape[:2] != img.shape[:2]:
                    depth_gt = np.array(Image.fromarray(depth_gt).resize((img.shape[1], img.shape[0])))
                    depth_pr = np.array(Image.fromarray(depth_pr).resize((img.shape[1], img.shape[0])))
                
                # Create standardized 2x3 panel
                row1 = np.concatenate([seg_gt, img, seg_pr], axis=1)
                row2 = np.concatenate([depth_gt, img, depth_pr], axis=1)
                panel = np.concatenate([row1, row2], axis=0)
                
                if filenames is not None and i < len(filenames):
                    stem = os.path.splitext(os.path.basename(filenames[i]))[0]
                    out_filename = f"{stem}.png"
                else:
                    out_filename = f"epoch{self.current_epoch:03d}_step{self.global_step:06d}_{i}.png"
                out_path = os.path.join(self.base_vis_dir, stage, out_filename)
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
                with Image.fromarray(panel) as img:
                    img.save(out_path)
                
        except Exception as e:
            warnings.warn(f"Failed to save PIL visualization: {e}")
    
    

    def configure_optimizers(self):
        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=0.01)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=max(1, self.t_max), eta_min=self.final_lr
        )
        return {
            "optimizer": optimizer,
            "lr_scheduler": {"scheduler": scheduler, "interval": "epoch"},
        }


# ============================================================================
# Dataset Builder
# ============================================================================
def build_esanet_datasets(dataset_root: Path, image_size: Tuple[int, int]):
    """
    ESANet ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì„ ìœ„í•œ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        image_size: ëª¨ë¸ ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (width, height)
        
    Returns:
        tuple: (train_ds, val_ds, test_ds) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
        
    ë°ì´í„°ì…‹ êµ¬ì¡°:
        dataset_root/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ images/     # RGB ì´ë¯¸ì§€
        â”‚   â”œâ”€â”€ masks/      # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬
        â”‚   â””â”€â”€ depth/      # ê¹Šì´ ë§µ
        â”œâ”€â”€ val/
        â”‚   â”œâ”€â”€ images/
        â”‚   â”œâ”€â”€ masks/
        â”‚   â””â”€â”€ depth/
        â””â”€â”€ test/
            â”œâ”€â”€ images/
            â”œâ”€â”€ masks/
            â””â”€â”€ depth/
    """
    # ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì •
    train_images = dataset_root / "train" / "images"
    train_masks = dataset_root / "train" / "masks"
    train_depth = dataset_root / "train" / "depth"
    
    val_images = dataset_root / "val" / "images"
    val_masks = dataset_root / "val" / "masks"
    val_depth = dataset_root / "val" / "depth"
    
    test_images = dataset_root / "test" / "images"
    test_masks = dataset_root / "test" / "masks"
    test_depth = dataset_root / "test" / "depth"

    # ImageNet í‘œì¤€ ì •ê·œí™” íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    mean, std = get_preprocessing_params("esanet")

    # í•™ìŠµ ë°ì´í„°ì…‹: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± ìœ ì§€
    train_ds = RGBDepthMultiTaskDataset(
        train_images, train_masks, train_depth,
        image_size=image_size, mean=mean, std=std, is_train=True
    )
    
    # ê²€ì¦ ë°ì´í„°ì…‹: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± ìœ ì§€
    val_ds = RGBDepthMultiTaskDataset(
        val_images, val_masks, val_depth,
        image_size=image_size, mean=mean, std=std, is_train=False
    )
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± ìœ ì§€
    test_ds = RGBDepthMultiTaskDataset(
        test_images, test_masks, test_depth,
        image_size=image_size, mean=mean, std=std, is_train=False
    )
    
    return train_ds, val_ds, test_ds


# ============================================================================
# Collate Function (avoids non-resizable storage issues)
# ============================================================================
def collate_esanet_batch(batch):
    """
    ESANet ë°°ì¹˜ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ìŠ¤íƒí•˜ëŠ” ì»¤ìŠ¤í…€ ì½œë ˆì´íŠ¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Args:
        batch: ìƒ˜í”Œ ë¦¬ìŠ¤íŠ¸, ê° ìƒ˜í”Œì€ (image, depth, mask, depth_target, filename) íŠœí”Œ
        
    Returns:
        tuple: ìŠ¤íƒëœ ë°°ì¹˜ í…ì„œë“¤
            - imgs: RGB ì´ë¯¸ì§€ ë°°ì¹˜ [B, 3, H, W]
            - depths: ê¹Šì´ ì…ë ¥ ë°°ì¹˜ [B, 1, H, W]  
            - masks: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ë°°ì¹˜ [B, H, W]
            - depth_targets: ê¹Šì´ íƒ€ê²Ÿ ë°°ì¹˜ [B, H, W]
            - filenames: íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë©”ëª¨ë¦¬ ë¦¬ì‚¬ì´ì¦ˆ ì˜¤ë¥˜ ë°©ì§€: contiguous() í˜¸ì¶œë¡œ ë…ë¦½ì  ìŠ¤í† ë¦¬ì§€ ë³´ì¥
    - ë°°ì¹˜ í¬ê¸° ë™ì  ì²˜ë¦¬: ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ì— ëŒ€ì‘
    - íŒŒì¼ëª… ì²˜ë¦¬: í…ŒìŠ¤íŠ¸ ì‹œ íŒŒì¼ëª… ì •ë³´ ë³´ì¡´
    """
    # ë°°ì¹˜ êµ¬ì„± ìš”ì†Œë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    imgs = []
    depths = []
    masks = []
    depth_targets = []
    filenames = []
    
    # ê° ìƒ˜í”Œì„ ìˆœíšŒí•˜ë©° í…ì„œë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬
    for sample in batch:
        if len(sample) >= 4:
            img, depth, mask, depth_t = sample[:4]
            # contiguous() í˜¸ì¶œë¡œ ë…ë¦½ì  ìŠ¤í† ë¦¬ì§€ ë³´ì¥ (ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ë°©ì§€)
            imgs.append(img.contiguous())
            depths.append(depth.contiguous())
            masks.append(mask.contiguous())
            depth_targets.append(depth_t.contiguous())
            
            # íŒŒì¼ëª…ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€
            if len(sample) >= 5:
                filenames.append(sample[4])
        else:
            raise RuntimeError("Unexpected batch item length: expected >=4")
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì¹˜ í…ì„œë¡œ ìŠ¤íƒ
    imgs = torch.stack(imgs, dim=0)
    depths = torch.stack(depths, dim=0)
    masks = torch.stack(masks, dim=0)
    depth_targets = torch.stack(depth_targets, dim=0)
    
    # íŒŒì¼ëª…ì´ ìˆìœ¼ë©´ í•¨ê»˜ ë°˜í™˜, ì—†ìœ¼ë©´ í…ì„œë§Œ ë°˜í™˜
    if filenames:
        return imgs, depths, masks, depth_targets, filenames
    return imgs, depths, masks, depth_targets

# ============================================================================
# Main
# ============================================================================
def parse_args():
    """
    ëª…ë ¹í–‰ ì¸ìˆ˜ë¥¼ íŒŒì‹±í•˜ì—¬ ì„¤ì • íŒŒì¼ ê²½ë¡œì™€ ì˜µì…˜ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        argparse.Namespace: íŒŒì‹±ëœ ëª…ë ¹í–‰ ì¸ìˆ˜
            - config: ì„¤ì • íŒŒì¼ ê²½ë¡œ (YAML ë˜ëŠ” JSON)
            - create_default_config: ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„± ì—¬ë¶€
    """
    parser = argparse.ArgumentParser(description="Train ESANet Multi-Task (Seg + Depth)")
    # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì • íŒŒì¼ì„ ì§€ì •í•˜ë„ë¡ ê°•ì œ
    parser.add_argument("--config", type=str, required=True, help="Path to config.yaml or config.json")
    parser.add_argument("--create-default-config", action="store_true", help="Create default config file and exit")
    return parser.parse_args()


def main() -> None:
    """
    ESANet ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµì˜ ë©”ì¸ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ì„¤ì • íŒŒì¼ ë¡œë“œ ë° ê²€ì¦
    - ë°ì´í„°ì…‹ êµ¬ì¶• ë° DataLoader ìƒì„±
    - ëª¨ë¸ ì´ˆê¸°í™” ë° ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ë¡œë“œ
    - PyTorch Lightning Trainer ì„¤ì • ë° í•™ìŠµ ì‹¤í–‰
    - ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    - í•™ìŠµ ê²°ê³¼ ìš”ì•½ ë° ì‹œê°í™” ì €ì¥
    
    ì²˜ë¦¬ ìˆœì„œ:
    1) ì „ì—­ ì‹œë“œ ì„¤ì • ë° ì¬í˜„ì„± ë³´ì¥
    2) ì„¤ì • íŒŒì¼ ë¡œë“œ (YAML ìš°ì„ , JSON í´ë°±)
    3) ë°ì´í„°ì…‹ ê²½ë¡œ ê²€ì¦ ë° êµ¬ì¶•
    4) ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
    5) ì½œë°± ë° ë¡œê±° ì„¤ì •
    6) í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    7) ê²°ê³¼ ìš”ì•½ ë° ì €ì¥
    """
    if not ESANET_AVAILABLE:
        print("âŒ ESANet ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì—­ ê²°ì •ë¡  ì„¤ì •: ëª¨ë“  ëœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ì¬í˜„ì„± ë³´ì¥
    set_global_determinism(42)
    pl.seed_everything(42, workers=True)
    
    # Tensor Core ìµœì í™” (RTX 4090ìš©)
    # 16ë¹„íŠ¸ í˜¼í•© ì •ë°€ë„ í•™ìŠµ ì‹œ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì„¤ì •
    if torch.cuda.is_available():
        torch.set_float32_matmul_precision('medium')
    args = parse_args()
    
    # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„± ìš”ì²­ ì²˜ë¦¬
    if args.create_default_config:
        from config import create_default_config_file
        create_default_config_file("default_config.yaml")
        print("âœ… Default configuration file created: default_config.yaml")
        return
    
    # ì„¤ì • íŒŒì¼ ë¡œë“œ (ì™¸ë¶€ ëª¨ë“ˆ ì—†ì´ YAML ì§ì ‘ ë¡œë“œ)
    def _dict_to_namespace(obj):
        from types import SimpleNamespace
        if isinstance(obj, dict):
            return SimpleNamespace(**{k: _dict_to_namespace(v) for k, v in obj.items()})
        if isinstance(obj, list):
            return [ _dict_to_namespace(v) for v in obj ]
        return obj

    cfg_path = args.config
    if not os.path.isabs(cfg_path):
        cfg_path = os.path.abspath(cfg_path)
    if not os.path.exists(cfg_path):
        raise FileNotFoundError(f"Config file not found: {cfg_path}")

    if cfg_path.endswith('.yaml') or cfg_path.endswith('.yml'):
        try:
            import yaml
        except Exception as e:
            raise ImportError(f"YAML ë¡œë”(pyyaml)ê°€ í•„ìš”í•©ë‹ˆë‹¤: {e}")
        with open(cfg_path, 'r', encoding='utf-8') as f:
            cfg_dict = yaml.safe_load(f) or {}
        config = _dict_to_namespace(cfg_dict)
        print(f"âœ… Configuration loaded from {cfg_path}")
    else:
        # JSON í´ë°± - ì£¼ì„ ì†ì‹¤ ê²½ê³ 
        warnings.warn("JSON configëŠ” ì£¼ì„ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. YAML ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        with open(cfg_path, 'r', encoding='utf-8') as f:
            cfg_dict = json.load(f)
        config = _dict_to_namespace(cfg_dict)
        print(f"âœ… Configuration (JSON) loaded from {cfg_path}")

    # ì„¤ì • ì •ë³´ ë””ë²„ê·¸ ì¶œë ¥
    print(f"ğŸ“‹ Config type: {type(config)}")
    print(f"ğŸ“‹ Dataset root: {getattr(getattr(config, 'data', object()), 'dataset_root', 'N/A')}")
    
    # CUDA í™˜ê²½ ì •ë³´ ì¶œë ¥
    print("=" * 80)
    print(f"CUDA Available: {torch.cuda.is_available()}")
    print(f"CUDA Device Count: {torch.cuda.device_count()}")
    if torch.cuda.is_available():
        print(f"CUDA Device Name: {torch.cuda.get_device_name(0)}")
    print("=" * 80)
    
    # ì„¤ì • ê¸°ë°˜ ê²½ë¡œ ì„¤ì •
    dataset_root = Path(os.path.abspath(config.data.dataset_root))
    output_dir = Path(os.path.abspath(config.output_dir))
    output_dir.mkdir(parents=True, exist_ok=True)

    # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • (í•™ìŠµ + ê²€ì¦ + í…ŒìŠ¤íŠ¸)
    _run_start_time = time.time()

    # ë°ì´í„°ì…‹ êµ¬ì¶• (ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì¼ê´€ì„± ìœ ì§€)
    train_ds, val_ds, test_ds = build_esanet_datasets(
        dataset_root, (config.model.width, config.model.height)
    )
    
    print(f"Dataset sizes: Train={len(train_ds)}, Val={len(val_ds)}, Test={len(test_ds)}")

    # í•™ìŠµìš© DataLoader: ì…”í”Œ í™œì„±í™”
    train_loader = DataLoader(
        train_ds, 
        batch_size=config.training.batch_size, 
        shuffle=True, 
        num_workers=config.data.num_workers, 
        pin_memory=config.data.pin_memory,
        persistent_workers=config.data.persistent_workers,
        worker_init_fn=dataloader_worker_init_fn,
        collate_fn=collate_esanet_batch,
    )
    
    # ê²€ì¦ìš© DataLoader: ì…”í”Œ ë¹„í™œì„±í™”
    val_loader = DataLoader(
        val_ds, 
        batch_size=config.training.batch_size, 
        shuffle=False, 
        num_workers=config.data.num_workers, 
        pin_memory=config.data.pin_memory,
        persistent_workers=config.data.persistent_workers,
        worker_init_fn=dataloader_worker_init_fn,
        collate_fn=collate_esanet_batch,
    )
    
    # í…ŒìŠ¤íŠ¸ìš© DataLoader: ì…”í”Œ ë¹„í™œì„±í™”
    test_loader = DataLoader(
        test_ds, 
        batch_size=config.training.batch_size, 
        shuffle=False, 
        num_workers=config.data.num_workers, 
        pin_memory=config.data.pin_memory,
        persistent_workers=config.data.persistent_workers,
        worker_init_fn=dataloader_worker_init_fn,
        collate_fn=collate_esanet_batch,
    )

    steps_per_epoch = max(1, len(train_loader))
    
    # ì‹œê°í™” ë””ë ‰í† ë¦¬ ê²½ë¡œ í•´ê²°
    vis_dir = config.visualization.vis_dir
    if vis_dir.strip().lower() == "none":
        vis_dir = ""
    elif vis_dir.strip() == "":
        vis_dir = str(output_dir / "vis")
    if vis_dir:
        os.makedirs(vis_dir, exist_ok=True)

    # ì‚¬ì „í›ˆë ¨ ê°€ì¤‘ì¹˜ ê²½ë¡œ í•´ê²°: ì„¤ì • ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ NYUv2 ê°€ì¤‘ì¹˜ ì‚¬ìš©
    use_pretrained = getattr(config.model, 'use_pretrained', True)
    pretrained_path_cfg = getattr(config.model, 'pretrained_path', None)
    default_pretrained_path = \
        "/home/shinds/my_document/DLFromScratch5/test/vae/sss/ESANet/trained_models/nyuv2/r34_NBt1D_scenenet.pth"
    pretrained_path_to_use = None
    if use_pretrained:
        pretrained_path_to_use = pretrained_path_cfg if pretrained_path_cfg else (
            default_pretrained_path if os.path.exists(default_pretrained_path) else None
        )
    if use_pretrained and pretrained_path_to_use:
        print(f"âœ… Using ESANet pretrained weights: {pretrained_path_to_use}")
    elif use_pretrained:
        print("ğŸ“ No ESANet pretrained weights found; training from scratch...")
    else:
        print("â„¹ï¸ Config: use_pretrained=False, training from scratch.")

    # ESANet ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ ì´ˆê¸°í™”
    model = LightningESANetMTL(
        height=config.model.height,
        width=config.model.width,
        num_classes=config.model.num_classes,
        encoder_rgb=config.model.encoder_rgb,
        encoder_depth=config.model.encoder_depth,
        encoder_block=config.model.encoder_block,
        lr=config.training.lr,
        scheduler_t_max=getattr(config.training, 'scheduler_t_max', config.training.epochs * steps_per_epoch),
        final_lr=getattr(config.training, 'final_lr', 1e-5),
        loss_type=config.training.loss_type,
        seg_loss_weight=config.training.seg_loss_weight,
        depth_loss_weight=config.training.depth_loss_weight,
        use_uncertainty_weighting=config.training.use_uncertainty_weighting,
        use_dwa_weighting=config.training.use_dwa_weighting,
        save_vis_dir=vis_dir,
        vis_max=config.visualization.vis_max,
        save_root_dir=str(output_dir),
        pretrained_path=pretrained_path_to_use,
    )

    # í•™ìŠµ ì½œë°± ì„¤ì •
    # mIoU ê¸°ë°˜ ì²´í¬í¬ì¸íŠ¸: ì„¸ê·¸ë©˜í…Œì´ì…˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥
    ckpt_miou = ModelCheckpoint(
        dirpath=str(output_dir),
        filename="esanet-mtl-miou-{epoch:02d}-{val_miou:.4f}",
        monitor="val_miou",
        mode="max",
        save_top_k=1,  # ìµœê³  mIoUë§Œ ì €ì¥
        save_last=False,  # ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¹„í™œì„±í™” (last.ckpt ë°©ì§€)
    )
    
    # AbsRel ê¸°ë°˜ ì²´í¬í¬ì¸íŠ¸: ê¹Šì´ ì¶”ì • ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥
    ckpt_absrel = ModelCheckpoint(
        dirpath=str(output_dir),
        filename="esanet-mtl-absrel-{epoch:02d}-{val_abs_rel:.4f}",
        monitor="val_abs_rel",
        mode="min",
        save_top_k=1,  # ìµœì†Œ AbsRelë§Œ ì €ì¥
    )

    # ì¡°ê¸° ì¢…ë£Œ: ê¹Šì´ ì¶”ì • ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµ ì¤‘ë‹¨
    # ì„¤ì • ê¸°ë°˜ ì¡°ê¸° ì¢…ë£Œ ì„¤ì •
    es_monitor = getattr(config.training, 'early_stop_monitor', 'val_abs_rel')
    # YAMLì—ì„œ ë°˜ë“œì‹œ ê°€ì ¸ì˜¤ë„ë¡ í•˜ë“œì½”ë”© ê¸°ë³¸ê°’ ì œê±°
    es_patience = config.training.early_stop_patience
    es_min_delta = config.training.early_stop_min_delta
    # ëª¨ë‹ˆí„°ëª…ì— ë”°ë¼ ëª¨ë“œ ìë™ ì„ ì •
    es_mode = 'min'
    try:
        mon_lower = str(es_monitor).lower()
        if 'iou' in mon_lower or 'acc' in mon_lower:
            es_mode = 'max'
    except Exception:
        pass
    
    

    early_stop = EarlyStopping(
        monitor=es_monitor,
        min_delta=es_min_delta,
        patience=es_patience,
        verbose=True,  # PyTorch Lightningì´ ì§ì ‘ ë¡œê·¸ ì¶œë ¥
        mode=es_mode,
    )

    # TensorBoard ë¡œê±°: output_dirì— ì§ì ‘ ë¡œê·¸ ì €ì¥ (version_x ì¤‘ì²© ë°©ì§€)
    logger = TensorBoardLogger(save_dir=str(output_dir), name="", version="")

    # PyTorch Lightning Trainer ì„¤ì •
    trainer = pl.Trainer(
        max_epochs=config.training.epochs,
        precision=config.system.precision,
        default_root_dir=str(output_dir),
        callbacks=[ckpt_miou, ckpt_absrel, early_stop],
        logger=logger,
        accelerator=config.system.accelerator,
        devices=config.system.devices,
        gradient_clip_val=config.training.gradient_clip_val,
        accumulate_grad_batches=config.training.accumulate_grad_batches,
        log_every_n_steps=10,
    )
    
    # í•™ìŠµ ì‹œì‘
    trainer.fit(model, train_loader, val_loader, ckpt_path=(config.system.ckpt_path or None))
    
    # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¡œ ê²€ì¦ ìˆ˜í–‰
    print("=" * 80)
    print("Validating with best checkpoint (by lowest val_abs_rel)...")
    print("=" * 80)
    best_val_results = trainer.validate(dataloaders=val_loader, ckpt_path=ckpt_absrel.best_model_path)
    
    # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
    print("=" * 80)
    print("Testing with best checkpoint (by lowest val_abs_rel)...")
    print("=" * 80)
    test_results = trainer.test(model, test_loader, ckpt_path=ckpt_absrel.best_model_path)

    # ì´ ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
    _elapsed_sec = max(0.0, time.time() - _run_start_time)
    _elapsed_h = int(_elapsed_sec // 3600)
    _elapsed_m = int((_elapsed_sec % 3600) // 60)
    _elapsed_s = int(_elapsed_sec % 60)
    
    # í•™ìŠµ ê²°ê³¼ ìš”ì•½
    # (on_test_epoch_endì—ì„œ ê¸°ë¡ëœ í´ë˜ìŠ¤ë³„ IoUëŠ” TensorBoard ì´ë²¤íŠ¸ì— ì €ì¥ë¨)
    summary = {
        "best_checkpoint_miou": ckpt_miou.best_model_path,
        "best_miou": float(ckpt_miou.best_model_score) if ckpt_miou.best_model_score is not None else None,
        "best_checkpoint_absrel": ckpt_absrel.best_model_path,
        "best_absrel": float(ckpt_absrel.best_model_score) if ckpt_absrel.best_model_score is not None else None,
        "best_val_results": best_val_results,
        "test_results": test_results,
        "training_time_sec": round(_elapsed_sec, 2),
        "training_time_hms": f"{_elapsed_h:02d}:{_elapsed_m:02d}:{_elapsed_s:02d}",
    }
    # í´ë˜ìŠ¤ë³„ mIoUë¥¼ ìµœì¢… ë¡œê·¸ íŒŒì¼ì— í•¨ê»˜ ì €ì¥ (validationê³¼ test ì—í­ ëˆ„ì ì¹˜ë¥¼ ì´ìš©)
    try:
        class_names = [
            "background", "chamoe", "heatpipe", "path", "pillar", "topdownfarm", "unknown"
        ][: model.num_classes]
        
        # Validation í´ë˜ìŠ¤ë³„ IoU ê³„ì‚° ë¹„í™œì„±í™” (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # val_class_ious = {}
        # if hasattr(model, "_epoch_val_tp") and model._epoch_val_tp is not None:
        #     for i, class_name in enumerate(class_names):
        #         denom = (model._epoch_val_tp[i] + model._epoch_val_fp[i] + model._epoch_val_fn[i])
        #         if float(denom.detach().cpu().item()) > 0.0:
        #             iou_value = (model._epoch_val_tp[i] / denom).detach().cpu().item()
        #         else:
        #             iou_value = 0.0
        #         val_class_ious[class_name] = iou_value
        # summary["val_class_iou"] = val_class_ious
        
        # Test í´ë˜ìŠ¤ë³„ IoU ê³„ì‚° ë¹„í™œì„±í™” (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # test_class_ious = {}
        # if hasattr(model, "_epoch_test_tp") and model._epoch_test_tp is not None:
        #     for i, class_name in enumerate(class_names):
        #         denom = (model._epoch_test_tp[i] + model._epoch_test_fp[i] + model._epoch_test_fn[i])
        #         if float(denom.detach().cpu().item()) > 0.0:
        #             iou_value = (model._epoch_test_tp[i] / denom).detach().cpu().item()
        #         else:
        #             iou_value = 0.0
        #         test_class_ious[class_name] = iou_value
        # summary["test_class_iou"] = test_class_ious
    except Exception:
        pass

    print("=" * 80)
    print("í•™ìŠµì™„ë£Œ!")
    print("=" * 80)
    print(summary)
    print(f"â±ï¸ ëª‡ë¶„ì´ë‚˜ ê±¸ë ¸ì„ê¹Œìš”?: {_elapsed_h:02d}:{_elapsed_m:02d}:{_elapsed_s:02d} ({_elapsed_sec:.2f}s)")

    # ê²°ê³¼ë¥¼ CSVë¡œë„ ì €ì¥ (ìš”ì•½ ë° í…ŒìŠ¤íŠ¸/ê²€ì¦ ì£¼ìš” ì§€í‘œ)
    try:
        csv_file = output_dir / "results.csv"
        fieldnames = [
            "training_time_sec", "training_time_hms",
            "best_miou", "best_absrel",
        ]
        # ê²€ì¦/í…ŒìŠ¤íŠ¸ ì£¼ìš” ì§€í‘œë¥¼ í‰íƒ„í™”í•´ì„œ ì¶”ê°€
        if isinstance(best_val_results, list) and len(best_val_results) > 0 and isinstance(best_val_results[0], dict):
            for k in best_val_results[0].keys():
                if k not in fieldnames:
                    fieldnames.append(f"val::{k}")
        if isinstance(test_results, list) and len(test_results) > 0 and isinstance(test_results[0], dict):
            for k in test_results[0].keys():
                if k not in fieldnames:
                    fieldnames.append(f"test::{k}")
        # í´ë˜ìŠ¤ë³„ IoUëŠ” ì œê±°ë¨

        # í•œ ì¤„ ê¸°ë¡ìš© ë°ì´í„° êµ¬ì„±
        row = {
            "training_time_sec": summary.get("training_time_sec", None),
            "training_time_hms": summary.get("training_time_hms", None),
            "best_miou": summary.get("best_miou", None),
            "best_absrel": summary.get("best_absrel", None),
        }
        if isinstance(best_val_results, list) and len(best_val_results) > 0 and isinstance(best_val_results[0], dict):
            for k, v in best_val_results[0].items():
                row[f"val::{k}"] = v
        if isinstance(test_results, list) and len(test_results) > 0 and isinstance(test_results[0], dict):
            for k, v in test_results[0].items():
                row[f"test::{k}"] = v
        # í´ë˜ìŠ¤ë³„ IoUëŠ” ì œê±°ë¨

        # CSV ì‘ì„± (í—¤ë” í¬í•¨, ê¸°ì¡´ íŒŒì¼ ìˆìœ¼ë©´ ë®ì–´ì”€)
        with open(csv_file, "w", newline="", encoding="utf-8") as fcsv:
            writer = csv.DictWriter(fcsv, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerow(row)
        print(f"ğŸ§¾ CSV ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_file}")
    except Exception as e:
        warnings.warn(f"Failed to save CSV: {e}")

    # ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ training.log ì €ì¥
    try:
        log_file = output_dir / "training.log"
        lines = []
        lines.append("=" * 80)
        lines.append("ESANet Multi-Task Learning Results")
        lines.append("=" * 80)
        lines.append(f"Training Time: {summary.get('training_time_hms', '')} ({summary.get('training_time_sec', 0)}s)")
        if summary.get("best_miou") is not None:
            try:
                lines.append(f"Best mIoU: {float(summary['best_miou']):.4f}")
            except Exception:
                lines.append(f"Best mIoU: {summary['best_miou']}")
        if summary.get("best_absrel") is not None:
            try:
                lines.append(f"Best AbsRel: {float(summary['best_absrel']):.4f}")
            except Exception:
                lines.append(f"Best AbsRel: {summary['best_absrel']}")
        if summary.get("best_checkpoint_miou"):
            lines.append(f"Best mIoU Checkpoint: {summary['best_checkpoint_miou']}")
        if summary.get("best_checkpoint_absrel"):
            lines.append(f"Best AbsRel Checkpoint: {summary['best_checkpoint_absrel']}")
        lines.append("")
        # Validation block
        if isinstance(best_val_results, list) and len(best_val_results) > 0 and isinstance(best_val_results[0], dict):
            lines.append("Validation Results:")
            for k, v in best_val_results[0].items():
                lines.append(f"  {k}: {v}")
            lines.append("")
        
       
        
        # Test block
        if isinstance(test_results, list) and len(test_results) > 0 and isinstance(test_results[0], dict):
            lines.append("Test Results:")
            for k, v in test_results[0].items():
                lines.append(f"  {k}: {v}")
            lines.append("")
        
        # Test í´ë˜ìŠ¤ë³„ IoUëŠ” ì œê±°ë¨
        with open(log_file, "w", encoding="utf-8") as flog:
            flog.write("\n".join(lines))
        print(f"ğŸ—’ï¸ training.logê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {log_file}")
    except Exception as e:
        warnings.warn(f"Failed to save training.log: {e}")


if __name__ == "__main__":
    main()